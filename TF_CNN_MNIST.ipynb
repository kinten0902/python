{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "## Convolutional Neural Network　畳込みニューラルネットワーク\n",
    "## 卷积神经网络\n",
    "\n",
    "### (1) 入力層\n",
    "28x28=784次元のベクトルが入力ベクトルです。<br>\n",
    "数字の画像を784ピクセルに分割し、1次元=1ピクセルで情報を代入しています。\n",
    "\n",
    "### (2) 畳込み層1 -> プーリング層1\n",
    "2層準備。ゼロパディング(zero padding)という補完機能を利用しています。<br>\n",
    "ファイルの畳込みに対して、周縁データが欠落するのですが、その補完のためにパディングを用います。<br>\n",
    "（パディングの話で推測できるように、畳込み層では、入力の次元圧縮を行いません）<br>\n",
    "プーリング(pooling)では、畳込みで返された数値を圧縮します。<br>\n",
    "ここでは、最大プーリング(max pooling)という、最も基本的な手法を用いています。<br>\n",
    "プーリングでも、パディングを行うことがあります。<br>\n",
    "（重ね合わせがずれる領域が存在することがあるため）\n",
    "\n",
    "* ゼロパディング(zero padding)とは、画像や帳票などで数値を表現する際、<br>\n",
    "書式で指定した桁数に満たない部分をゼロで埋めることである。<br>\n",
    "例えば「123」を5桁で表す場合、2桁足りない部分をゼロで埋めて「00123」と表記する<br>\n",
    "* 最大プーリング(max pooling)とは、設定範囲のピクセルの中で最大値を選択する\n",
    "\n",
    "### (3) 畳込み層2 -> プーリング層2\n",
    "(2)の繰り返しでさらに圧縮 -> この段階で7x7=49次元まで落とす予定です。\n",
    "\n",
    "### (4) 全結合層(高密度結合層)\n",
    "抽出したプーリング層からの出力層を入力層に送り、NNのような処理をかけます。<br>\n",
    "活性化関数はReLUです。\n",
    "\n",
    "### (5) クラス分類処理\n",
    "ソフトマックス関数の計算 -> 交差エントロピー誤差関数による評価\n",
    "\n",
    "https://qiita.com/icoxfog417/items/5fd55fad152231d706c2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络\n",
    "\n",
    "### 卷积神经网络一般包含这几层：\n",
    "* 输入层：用于数据的输入\n",
    "* 卷积层：使用卷积核进行特征提取和特征映射\n",
    "* 激励层：由于卷积也是一种线性运算，因此需要增加非线性映射\n",
    "* 池化层：进行下采样，对特征图稀疏处理，减少数据运算量。\n",
    "* 全连接层：通常在CNN的尾部进行重新拟合，减少特征信息的损失\n",
    "* 输出层：用于输出结果\t\n",
    "### 中间还可能使用一些其他的功能层：\n",
    "* 归一化层（Batch Normalization）：在CNN中对特征的归一化\n",
    "* 切分层：对某些（图片）数据的进行分区域的单独学习\n",
    "* 融合层：对独立进行特征学习的分支进行融合\n",
    "\n",
    "### 输入层：\n",
    "对于黑白的28x28的图片，输入层就是一个28x28的二维神经元。<br>\n",
    "对于RGB彩色的28x28的图片，输入层则是一个3x28x28的三维神经元，每一个颜色通道都有一个28x28的矩阵。<br>\n",
    "\n",
    "### 卷积层：\n",
    "* local receptive fields（感受视野）\n",
    "* convolution kernel（卷积核）\n",
    "* stride（步长）\n",
    "* pad（边界扩充）\n",
    "* feature map（特征图）\n",
    "* shared weights（共享权值）\n",
    "\n",
    "假设输入层的是一个28×28的的二维神经元，我们定义5×5的一个区域，<br>\n",
    "让后一层的1个神经元与输入层的5×5个神经元相连，这个5×5的区域就称之为【感受视野】。<br>\n",
    "可以理解为后一层中的1个神经元，具有一个固定大小的感受视野去感受上一层的部分特征。<br>\n",
    "在全连接神经网络中，后一层中的神经元的感受视野足够大乃至可以看到上一层的所有特征。<br>\n",
    "而在卷积神经网络中，后一层中的神经元的感受视野比较小，只能看到上一层的部分特征，<br>\n",
    "上一层的其他特征可以通过平移感受视野来由同层的其他神经元去感受。<br>\n",
    "\n",
    "假设移动的步长为1：从左到右扫描，每次移动1格，扫描完之后，再向下移动1格，再次从左到右扫描。<br>\n",
    "最终，一个28×28的输入层通过一个5×5的感受视野就能获得一个24x24的后一层。<br>\n",
    "\n",
    "感受视野中的权重w矩阵就称为【卷积核】，1个感受视野带有1个卷积核。<br>\n",
    "将感受视野对输入的扫描间隔称为【步长】。<br>\n",
    "当步长大于1，为了扫描到边缘的一些特征，感受视野可能会出界，<br>\n",
    "这时就需要对输入层进行【边界扩充】，填充的值可以设为0或其他值<br>\n",
    "通过感受视野扫描生成的下一层神经元矩阵，称为一个【特征图】。<br>\n",
    "因此在同一个特征图上的神经元使用的卷积核时相同的，这些神经元【共享权值】和附带的偏移值。<br>\n",
    "一个特征图对应一个卷积核，如果使用3个不同的卷积核，就可以输出3个特征图。<br>\n",
    "\n",
    "卷积层的好处就是，需要训练的参数大大减少。<br>\n",
    "对于一个28x28的输入层，在全链接神经网络中，需要训练的参数是28x28+28=812个，<br>\n",
    "在有3个卷积核的卷积层中，需要训练的参数是(5x5+1)x3=78个。<br>\n",
    "\n",
    "对于输入时28x28的RGB图片，即输入的是一个3x28x28的三维神经元，<br>\n",
    "这时卷积核的大小除了长宽还有深度例如3x5x5。<br>\n",
    "\n",
    "### 激励层：\n",
    "激励层主要对卷积层的输出进行一个非线性映射，因为卷积层的计算还是一种线性计算。<br>\n",
    "使用的激励函数一般为ReLu函数。<br>\n",
    "卷积层和激励层通常合并在一起称为卷积层。<br>\n",
    "\n",
    "### 池化层：\n",
    "* filter（池化视野）\n",
    "\n",
    "当输入经过卷积层时，若感受视野比较小，步长比较小，得到的特征图还是比较大，<br>\n",
    "可以通过池化层来对每一个特征图进行降维操作，输出的((深度))还是不变的，依然为特征图的个数。<br>\n",
    "\n",
    "池化层也有一个【池化视野】来对特征图矩阵进行扫描，对池化视野中的矩阵值进行计算，<br>\n",
    "一般有两种计算方式：\n",
    "1. Max pooling：取池化视野矩阵中的最大值\n",
    "2. Average pooling：取池化视野矩阵中的平均值\n",
    "\n",
    "例如3个24x24的特征图，通过一个2x2的池化视野，步长为2的采样后，<br>\n",
    "就可得到3个12x12的特征矩阵。<br>\n",
    "\n",
    "### 归一化层：\n",
    "1. Batch Normalization（批量归一化）\n",
    "是一种在神经网络中间进行的预处理操作，即在上一层的输入归一化处理后再进入网络的下一层，<br>\n",
    "这样可以有效地防止梯度弥散，加速网络训练。<br>\n",
    "在卷积神经网络中进行批量归一化时，一般对未进行ReLu激活的特征图进行批量归一化，<br>\n",
    "输出后再作为激励层的输入，可达到调整激励函数偏导的作用。<br>\n",
    "\n",
    "2. Local Response Normalization（近邻归一化）\n",
    "主要发生在不同的相邻的卷积核（经过ReLu之后）的输出之间，<br>\n",
    "即输入是发生在不同的经过ReLu之后的特征图中。<br>\n",
    "与批量归一化的区别是，批量归一化依据mini batch的数据,近邻归一仅需要自己来决定，BN训练中有学习参数;<br>\n",
    "批量归一化主要发生在不同的样本之间，近邻归一化主要发生在不同的卷积核的输出之间。<br>\n",
    "\n",
    "### 切分层：\n",
    "在一些应用中,需要对图片进行切割，独立地对某一部分区域进行单独学习。<br>\n",
    "这样可以对特定部分进行通过调整 感受视野 进行力度更大的学习。<br>\n",
    "\n",
    "### 融合层：\n",
    "融合层可以对切分层进行融合，也可以对不同大小的卷积核学习到的特征进行融合。<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import input_data\n",
    "import numpy as np\n",
    "import time\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n"
     ]
    }
   ],
   "source": [
    "# Network Parameters\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "train_dropout = 0.5\n",
    "test_dropout = 1.0\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "batch_size = 50\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "print(total_batch)\n",
    "training_epochs = 30\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_input])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, n_classes])\n",
    "\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.truncated_normal(stddev=0.1, shape=[5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.truncated_normal(stddev=0.1, shape=[5, 5, 32, 64])),\n",
    "    'wf1': tf.Variable(tf.truncated_normal(stddev=0.1, shape=[7 * 7 * 64, 1024])),\n",
    "    'out': tf.Variable(tf.truncated_normal(stddev=0.1, shape=[1024, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.constant(value=0.1, shape=[32])),\n",
    "    'bc2': tf.Variable(tf.constant(value=0.1, shape=[64])),\n",
    "    'bf1': tf.Variable(tf.constant(value=0.1, shape=[1024])),\n",
    "    'out': tf.Variable(tf.constant(value=0.1, shape=[n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "\n",
    "def CNN(x, weights, biases, dropout):\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # First convolutional layer - maps one image to 32 feature maps\n",
    "    conv1 = tf.nn.conv2d(x, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv1 = tf.add(conv1, biases['bc1'])\n",
    "    conv1_relu = tf.nn.relu(conv1)\n",
    "\n",
    "    # First pooling layer - downsamples by 2X\n",
    "    pool1 = tf.nn.max_pool(conv1_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Second convolutional layer - maps 32 feature maps to 64\n",
    "    conv2 = tf.nn.conv2d(pool1, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "    conv2 = tf.add(conv2, biases['bc2'])\n",
    "    conv2_relu = tf.nn.relu(conv2)\n",
    "\n",
    "    # Second pooling layer - downsamples by 2X\n",
    "    pool2 = tf.nn.max_pool(conv2_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Fully connected layer - after 2 round downsampling,\n",
    "    # 28x28 image is down to 7x7x64 feature maps\n",
    "    # maps this to 1024 features\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    fc1 = tf.add(tf.matmul(pool2_flat, weights['wf1']), biases['bf1'])\n",
    "    fc1_relu = tf.nn.relu(fc1)\n",
    "\n",
    "    # Dropout - controls the complexity of the model\n",
    "    # -- prevents co-adaptation of features\n",
    "    fc1_drop = tf.nn.dropout(fc1_relu, dropout)\n",
    "\n",
    "    # Map the 1024 features to 10 classes, one for each digit\n",
    "    out = tf.add(tf.matmul(fc1_drop, weights['out']), biases['out'])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "y_pred = CNN(X, weights, biases, keep_prob)\n",
    "y_softmax = tf.nn.softmax(y_pred)\n",
    "\n",
    "# Define loss and optimizer\n",
    "# type 1:\n",
    "# loss = tf.reduce_mean(\n",
    "#     -tf.reduce_sum(Y * tf.log(y_softmax), reduction_indices=[1]))\n",
    "# type 2:\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=y_pred))\n",
    "# type 3:\n",
    "# loss = tf.reduce_mean(\n",
    "#     tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=y_pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Evaluate model\n",
    "pred = tf.argmax(y_pred, 1)\n",
    "true = tf.argmax(Y, 1)\n",
    "correct_prediction = tf.equal(pred, true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch:1100 train_acc=1.000 test_acc=0.968 train_cost=0.573\n",
      "Epoch: 2 Batch:1100 train_acc=0.940 test_acc=0.977 train_cost=0.140\n",
      "Epoch: 3 Batch:1100 train_acc=1.000 test_acc=0.985 train_cost=0.094\n",
      "Epoch: 4 Batch:1100 train_acc=1.000 test_acc=0.985 train_cost=0.069\n",
      "Epoch: 5 Batch:1100 train_acc=0.980 test_acc=0.989 train_cost=0.056\n",
      "Epoch: 6 Batch:1100 train_acc=1.000 test_acc=0.990 train_cost=0.045\n",
      "Epoch: 7 Batch:1100 train_acc=1.000 test_acc=0.991 train_cost=0.038\n",
      "Epoch: 8 Batch:1100 train_acc=1.000 test_acc=0.992 train_cost=0.032\n",
      "Epoch: 9 Batch:1100 train_acc=0.980 test_acc=0.991 train_cost=0.027\n",
      "Epoch:10 Batch:1100 train_acc=0.980 test_acc=0.992 train_cost=0.024\n",
      "Epoch:11 Batch:1100 train_acc=1.000 test_acc=0.989 train_cost=0.020\n",
      "Epoch:12 Batch:1100 train_acc=1.000 test_acc=0.992 train_cost=0.018\n",
      "Epoch:13 Batch:1100 train_acc=1.000 test_acc=0.992 train_cost=0.016\n",
      "Epoch:14 Batch:1100 train_acc=1.000 test_acc=0.993 train_cost=0.014\n",
      "Epoch:15 Batch:1100 train_acc=1.000 test_acc=0.993 train_cost=0.012\n",
      "Epoch:16 Batch:1100 train_acc=0.980 test_acc=0.992 train_cost=0.009\n",
      "Epoch:17 Batch:1100 train_acc=1.000 test_acc=0.993 train_cost=0.009\n",
      "Epoch:18 Batch:1100 train_acc=1.000 test_acc=0.993 train_cost=0.008\n",
      "Epoch:19 Batch:1100 train_acc=1.000 test_acc=0.993 train_cost=0.008\n",
      "Epoch:20 Batch:1100 train_acc=1.000 test_acc=0.994 train_cost=0.006\n",
      "Epoch:21 Batch:1100 train_acc=1.000 test_acc=0.992 train_cost=0.007\n",
      "Epoch:22 Batch:1100 train_acc=0.980 test_acc=0.993 train_cost=0.006\n",
      "Epoch:23 Batch:1100 train_acc=1.000 test_acc=0.993 train_cost=0.004\n",
      "Epoch:24 Batch:1100 train_acc=1.000 test_acc=0.992 train_cost=0.006\n",
      "Epoch:25 Batch:1100 train_acc=0.980 test_acc=0.993 train_cost=0.005\n",
      "Epoch:26 Batch:1100 train_acc=1.000 test_acc=0.993 train_cost=0.004\n",
      "Epoch:27 Batch:1100 train_acc=1.000 test_acc=0.992 train_cost=0.004\n",
      "Epoch:28 Batch:1100 train_acc=1.000 test_acc=0.993 train_cost=0.003\n",
      "Epoch:29 Batch:1100 train_acc=1.000 test_acc=0.992 train_cost=0.004\n",
      "Epoch:30 Batch:1100 train_acc=1.000 test_acc=0.993 train_cost=0.003\n",
      "Process Time :119.94 s\n",
      "test accuracy=0.993\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Training cycle\n",
    "all_x_test = mnist.test.images\n",
    "all_y_test = mnist.test.labels\n",
    "start = time.time()\n",
    "for epoch_i in range(training_epochs):\n",
    "    ave_cost = 0\n",
    "    for batch_i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run(\n",
    "            [optimizer, loss],\n",
    "            feed_dict={\n",
    "                X: batch_x,\n",
    "                Y: batch_y,\n",
    "                keep_prob: train_dropout\n",
    "            })\n",
    "        ave_cost += c / total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch_i % 1 == 0:\n",
    "        train_acc = sess.run(\n",
    "            accuracy,\n",
    "            feed_dict={\n",
    "                X: batch_x,\n",
    "                Y: batch_y,\n",
    "                keep_prob: train_dropout\n",
    "            })\n",
    "        test_acc = sess.run(\n",
    "            accuracy,\n",
    "            feed_dict={\n",
    "                X: all_x_test,\n",
    "                Y: all_y_test,\n",
    "                keep_prob: test_dropout\n",
    "            })\n",
    "        print(\"Epoch:%2d Batch:%4d\" % (epoch_i + 1, batch_i + 1),\n",
    "              \"train_acc=%.3f\" % train_acc, \"test_acc=%.3f\" % test_acc,\n",
    "              \"train_cost=%5.3f\" % ave_cost)\n",
    "end = time.time()\n",
    "print(\"Process Time :%.2f s\" % (end - start))\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = sess.run(\n",
    "    accuracy,\n",
    "    feed_dict={\n",
    "        X: all_x_test,\n",
    "        Y: all_y_test,\n",
    "        keep_prob: test_dropout\n",
    "    })\n",
    "print(\"test accuracy=%.3f\" % acc)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
