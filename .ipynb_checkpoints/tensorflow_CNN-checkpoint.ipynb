{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "## Convolutional Neural Network　畳込みニューラルネットワーク\n",
    "\n",
    "### (1) 入力層\n",
    "28x28=784次元のベクトルが入力ベクトルです。<br>\n",
    "数字の画像を784ピクセルに分割し、1次元=1ピクセルで情報を代入しています。\n",
    "\n",
    "### (2) 畳込み層1 -> プーリング層1\n",
    "2層準備。ゼロパディング(zero padding)という補完機能を利用しています。<br>\n",
    "ファイルの畳込みに対して、周縁データが欠落するのですが、その補完のためにパディングを用います。<br>\n",
    "（パディングの話で推測できるように、畳込み層では、入力の次元圧縮を行いません）<br>\n",
    "プーリング(pooling)では、畳込みで返された数値を圧縮します。<br>\n",
    "ここでは、最大プーリング(max pooling)という、最も基本的な手法を用いています。<br>\n",
    "プーリングでも、パディングを行うことがあります。<br>\n",
    "（重ね合わせがずれる領域が存在することがあるため）\n",
    "\n",
    "* ゼロパディング(zero padding)とは、画像や帳票などで数値を表現する際、<br>\n",
    "書式で指定した桁数に満たない部分をゼロで埋めることである。<br>\n",
    "例えば「123」を5桁で表す場合、2桁足りない部分をゼロで埋めて「00123」と表記する<br>\n",
    "* 最大プーリング(max pooling)とは、設定範囲のピクセルの中で最大値を選択する\n",
    "\n",
    "### (3) 畳込み層2 -> プーリング層2\n",
    "(2)の繰り返しでさらに圧縮 -> この段階で7x7=49次元まで落とす予定です。\n",
    "\n",
    "### (4) 全結合層(高密度結合層)\n",
    "抽出したプーリング層からの出力層を入力層に送り、NNのような処理をかけます。<br>\n",
    "活性化関数はReLUです。\n",
    "\n",
    "### (5) クラス分類処理\n",
    "ソフトマックス関数の計算 -> 交差エントロピー誤差関数による評価\n",
    "\n",
    "https://qiita.com/icoxfog417/items/5fd55fad152231d706c2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Multilayer Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Initialization\n",
    "# 適当にノイズを含んだ重み行列作成関数（ノイズは対称性の除去と勾配ゼロ防止のため）\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# バイアス行列作成関数\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# Convolution and Pooling\n",
    "# 2次元畳込み関数\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# 2x2マックスプーリング関数\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(\n",
    "        x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# Placeholders\n",
    "# データ用可変2階テンソルを用意\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "# 正解用可変2階テンソルを用意\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "# 画像をリシェイブ：第2引数は画像数(-1は元サイズを保存するように自動計算)、縦X横、チャンネル\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# First Convolutional Layer\n",
    "# 1層目 畳み込み層\n",
    "# 畳み込み層のフィルタ重み：引数はパッチサイズ縦、パッチサイズ横、入力チャンネル数、出力チャンネル数\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "# 畳み込み層のバイアス\n",
    "b_conv1 = bias_variable([32])\n",
    "# 活性化関数ReLUでの畳み込み層を構築\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "# 2x2のマックスプーリング層を構築\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second Convolutional Layer\n",
    "# 2層目 畳み込み層\n",
    "# パッチサイズ縦、パッチサイズ横、入力チャンネル数、出力チャンネル数\n",
    "# 5x5フィルタで64チャネルを出力\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Densely Connected Layer\n",
    "# 全結合層\n",
    "\"\"\"\n",
    "オリジナル画像は28x28で、今回畳み込みでpadding='SAME'を指定しているため\n",
    "プーリングでのみ画像サイズが変わる。\n",
    "2x2プーリングで2x2でスライドも2x2なので\n",
    "縦横ともに各層で半減する。\n",
    "そのため、28/2/2=7が現在の画像サイズ\n",
    "\n",
    "全結合層にするために、1階テンソルに変形。\n",
    "画像サイズ縦と画像サイズ横とチャンネル数の積の次元\n",
    "出力は1024(この辺は決め)、あとはsoftmax regressionと同じ\n",
    "\"\"\"\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "# ドロップアウトを指定\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout Layer\n",
    "# 出力層\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "# 予測値\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価系の関数を用意\n",
    "# Loss(cross_entropy) and optimizer(train_step)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# テストのモデル\n",
    "pred = tf.argmax(y_conv, 1)\n",
    "true = tf.argmax(y_, 1)\n",
    "correct_prediction = tf.equal(pred, true)\n",
    "\n",
    "# 予測の精度\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    if i % 100 == 0:\n",
    "        train_acc = accuracy.eval(feed_dict={\n",
    "            x: batch[0],\n",
    "            y_: batch[1],\n",
    "            keep_prob: 1.0\n",
    "        })\n",
    "        test_acc = accuracy.eval(feed_dict={\n",
    "            x: mnist.test.images,\n",
    "            y_: mnist.test.labels,\n",
    "            keep_prob: 1.0\n",
    "        })\n",
    "        print \"step % 5d\" % (i), \"train_acc={:5f}\".format(\n",
    "            train_acc), \"test_acc={:5f}\".format(test_acc)\n",
    "end = time.time()\n",
    "print \"Process Time(s):{:.2f}\".format(end - start)\n",
    "print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images,\n",
    "    y_: mnist.test.labels,\n",
    "    keep_prob: 1.0\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
