{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import input_data\n",
    "import numpy as np\n",
    "import time\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    }
   ],
   "source": [
    "# Network Parameters\n",
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_classes = 10\n",
    "train_dropout = 0.9\n",
    "test_dropout = 1.0\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "print(total_batch)\n",
    "training_epochs = 30\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def NN(x, weights, biases, dropout):\n",
    "\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_1 = tf.nn.dropout(layer_1, dropout)\n",
    "\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_2 = tf.nn.dropout(layer_2, dropout)\n",
    "\n",
    "    out = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "y_pred = NN(X, weights, biases, keep_prob)\n",
    "y_softmax = tf.nn.softmax(y_pred)\n",
    "\n",
    "# Define loss and optimizer\n",
    "# type 1:\n",
    "# loss = tf.reduce_mean(\n",
    "#     -tf.reduce_sum(Y * tf.log(y_softmax), reduction_indices=[1]))\n",
    "# type 2:\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=y_pred))\n",
    "# type 3:\n",
    "# loss = tf.reduce_mean(\n",
    "#     tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=y_pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Evaluate model\n",
    "pred = tf.argmax(y_pred, 1)\n",
    "true = tf.argmax(Y, 1)\n",
    "correct_prediction = tf.equal(pred, true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 550 train_acc=0.860 test_acc=0.868 train_cost=262.059\n",
      "Epoch: 2 Batch: 550 train_acc=0.890 test_acc=0.903 train_cost=73.148\n",
      "Epoch: 3 Batch: 550 train_acc=0.950 test_acc=0.915 train_cost=45.090\n",
      "Epoch: 4 Batch: 550 train_acc=0.950 test_acc=0.923 train_cost=32.821\n",
      "Epoch: 5 Batch: 550 train_acc=0.940 test_acc=0.928 train_cost=25.269\n",
      "Epoch: 6 Batch: 550 train_acc=0.960 test_acc=0.935 train_cost=19.792\n",
      "Epoch: 7 Batch: 550 train_acc=0.940 test_acc=0.936 train_cost=16.378\n",
      "Epoch: 8 Batch: 550 train_acc=0.930 test_acc=0.940 train_cost=13.255\n",
      "Epoch: 9 Batch: 550 train_acc=0.920 test_acc=0.940 train_cost=11.279\n",
      "Epoch:10 Batch: 550 train_acc=0.980 test_acc=0.945 train_cost=9.282\n",
      "Epoch:11 Batch: 550 train_acc=0.980 test_acc=0.945 train_cost=7.844\n",
      "Epoch:12 Batch: 550 train_acc=0.970 test_acc=0.947 train_cost=6.957\n",
      "Epoch:13 Batch: 550 train_acc=0.960 test_acc=0.950 train_cost=5.939\n",
      "Epoch:14 Batch: 550 train_acc=0.980 test_acc=0.952 train_cost=5.232\n",
      "Epoch:15 Batch: 550 train_acc=0.970 test_acc=0.950 train_cost=4.461\n",
      "Epoch:16 Batch: 550 train_acc=1.000 test_acc=0.954 train_cost=3.910\n",
      "Epoch:17 Batch: 550 train_acc=0.990 test_acc=0.954 train_cost=3.506\n",
      "Epoch:18 Batch: 550 train_acc=0.970 test_acc=0.955 train_cost=3.047\n",
      "Epoch:19 Batch: 550 train_acc=1.000 test_acc=0.955 train_cost=2.698\n",
      "Epoch:20 Batch: 550 train_acc=0.950 test_acc=0.956 train_cost=2.501\n",
      "Epoch:21 Batch: 550 train_acc=0.980 test_acc=0.959 train_cost=2.165\n",
      "Epoch:22 Batch: 550 train_acc=0.950 test_acc=0.957 train_cost=2.066\n",
      "Epoch:23 Batch: 550 train_acc=0.970 test_acc=0.959 train_cost=1.941\n",
      "Epoch:24 Batch: 550 train_acc=0.990 test_acc=0.959 train_cost=1.547\n",
      "Epoch:25 Batch: 550 train_acc=0.990 test_acc=0.960 train_cost=1.544\n",
      "Epoch:26 Batch: 550 train_acc=0.980 test_acc=0.961 train_cost=1.322\n",
      "Epoch:27 Batch: 550 train_acc=0.990 test_acc=0.961 train_cost=1.227\n",
      "Epoch:28 Batch: 550 train_acc=0.990 test_acc=0.962 train_cost=1.164\n",
      "Epoch:29 Batch: 550 train_acc=1.000 test_acc=0.961 train_cost=1.057\n",
      "Epoch:30 Batch: 550 train_acc=1.000 test_acc=0.962 train_cost=1.000\n",
      "Process Time :18.87 s\n",
      "test accuracy=0.962\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Training cycle\n",
    "all_x_test = mnist.test.images\n",
    "all_y_test = mnist.test.labels\n",
    "start = time.time()\n",
    "for epoch_i in range(training_epochs):\n",
    "    ave_cost = 0\n",
    "    for batch_i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run(\n",
    "            [optimizer, loss],\n",
    "            feed_dict={\n",
    "                X: batch_x,\n",
    "                Y: batch_y,\n",
    "                keep_prob: train_dropout\n",
    "            })\n",
    "        ave_cost += c / total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch_i % 1 == 0:\n",
    "        train_acc = sess.run(\n",
    "            accuracy,\n",
    "            feed_dict={\n",
    "                X: batch_x,\n",
    "                Y: batch_y,\n",
    "                keep_prob: test_dropout\n",
    "            })\n",
    "        test_acc = sess.run(\n",
    "            accuracy,\n",
    "            feed_dict={\n",
    "                X: all_x_test,\n",
    "                Y: all_y_test,\n",
    "                keep_prob: test_dropout\n",
    "            })\n",
    "        print(\"Epoch:%2d Batch:%4d\" % (epoch_i + 1, batch_i + 1),\n",
    "              \"train_acc=%.3f\" % train_acc, \"test_acc=%.3f\" % test_acc,\n",
    "              \"train_cost=%5.3f\" % ave_cost)\n",
    "end = time.time()\n",
    "print(\"Process Time :%.2f s\" % (end - start))\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = sess.run(\n",
    "    accuracy,\n",
    "    feed_dict={\n",
    "        X: all_x_test,\n",
    "        Y: all_y_test,\n",
    "        keep_prob: test_dropout\n",
    "    })\n",
    "print(\"test accuracy=%.3f\" % acc)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
