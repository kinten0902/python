{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression\n",
    "\n",
    "softmax模型可以用来给不同的对象分配概率。<br>\n",
    "在训练更加复杂的模型时，最后一步也往往需要用softmax来分配概率。<br>\n",
    "\n",
    "softmax回归分两步：\n",
    "* 首先 对某个待分类对象属于某个类的“证据”相加求和\n",
    "* 然后 将这个“证据”的和和转化为概率\n",
    "\n",
    "例如计算一张图片是否属于某类。<br>\n",
    "使用加权的方法来累积计算这张图是否属于某类的“证据”。<br>\n",
    "如果图片的像素强有力的体现该图不属于某个类，则权重的数值为负数。<br>\n",
    "相反，则权重的数值为正。<br>\n",
    "还需要引入额外的“证据”，称之为偏置量(bias)<br>\n",
    "因此对于给定的输入图片$x$是属于第$i$类的总体“证据”可以表示为：\n",
    "\n",
    "$$\n",
    "evidence_i = \\sum_{i}W_{i,j}x_j + b_i\n",
    "$$\n",
    "\n",
    "其中$W_i$代表权重，$b_i$代表第$i$类的偏置量，$j$代表给定图片$x$的像素索引 用于求和<br>\n",
    "然后利用softmax函数可以把这些“证据”转化成概率$y$\n",
    "\n",
    "$$\n",
    "y = softmax(evidence)\n",
    "$$\n",
    "\n",
    "给定一张图$x$，它对于每一个类别的吻合度可以被softmax函数转换成一个概率值<br>\n",
    "softmax函数可以定义为：\n",
    "\n",
    "$$\n",
    "softmax(x) = normalize(exp(x))\n",
    "$$\n",
    "\n",
    "展开右边可以得到：\n",
    "\n",
    "$$\n",
    "softmax(x)_i = \\frac{exp(x_i)}{\\sum_{j}exp(x_j)}\n",
    "$$\n",
    "\n",
    "假设模型里的权值不可以是0或是负数，softmax会正则化这些权重值，<br>\n",
    "是它们的总和等于1，以此构建一个有效率的概率分布。\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3\n",
    "\\end{matrix}\n",
    "\\right] = softmax\\left(\n",
    "\\begin{matrix}\n",
    "W_{1,1}x_1 + W_{1,2}x_1 + W_{1,3}x_1 + b_1 \\\\\n",
    "W_{2,1}x_2 + W_{2,2}x_2 + W_{2,3}x_2 + b_2 \\\\\n",
    "W_{3,1}x_3 + W_{3,2}x_3 + W_{3,3}x_3 + b_3\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "转换成用 矩阵乘法和向量相加来表示：\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3\n",
    "\\end{matrix}\n",
    "\\right] = softmax\\left(\n",
    "\\left[\\begin{matrix}\n",
    "W_{1,1}&W_{1,2}&W_{1,3} \\\\\n",
    "W_{2,1}&W_{2,2}&W_{2,3} \\\\\n",
    "W_{3,1}&W_{3,2}&W_{3,3}\n",
    "\\end{matrix}\\right]\n",
    "\\cdot\n",
    "\\left[\\begin{matrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3\n",
    "\\end{matrix}\\right]\n",
    "+\n",
    "\\left[\\begin{matrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "b_3\n",
    "\\end{matrix}\\right]\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "简化为：\n",
    "$$\n",
    "y = softmax(W_x+b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估模型\n",
    "为了训练模型，通常需要定义一个指标来评估模型的好坏。<br>\n",
    "这个指标被称为成本(cost)或是损失(loss)，两者意思相同，然后尽量最小化这个指标。<br>\n",
    "非常常见的成本函数是“交叉熵”(cross-entropy):\n",
    "\n",
    "$$\n",
    "H_{y'}(y) = -\\sum_{i}y'_i\\log(y_i)\n",
    "$$\n",
    "\n",
    "其中y是预测的概率分布。<br>\n",
    "y‘是实际的分布。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算交叉熵\n",
    "（重要）<br>\n",
    "交叉熵不仅仅用来衡量单一的一对预测和真实值，<br>\n",
    "而是所有图片的交叉熵的总和。<br>\n",
    "对100个数据点的预测的表示比单一数据点的预测的表示能更好的描述模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kinten/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-2-30b112e5f9a4>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/kinten/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/kinten/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/kinten/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/kinten/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/kinten/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0 train_acc=0.490000 test_acc=0.358900\n",
      "train_pred_sm: [[0.00965373 0.0960416  0.0409211  0.25209102 0.1199263  0.08318483\n",
      "  0.01621814 0.14114763 0.2229003  0.01791538]\n",
      " [0.01413021 0.00908886 0.06840898 0.14124462 0.05146847 0.0304097\n",
      "  0.01488193 0.01460279 0.6550828  0.00068165]\n",
      " [0.00888283 0.00910231 0.03259642 0.03077484 0.529277   0.05112693\n",
      "  0.02561535 0.10416036 0.1873413  0.0211226 ]\n",
      " [0.0265422  0.05091213 0.07684216 0.06405663 0.2536274  0.12787005\n",
      "  0.0683338  0.08343241 0.18248521 0.06589801]\n",
      " [0.44239187 0.0078685  0.05784415 0.08579477 0.00743473 0.09756152\n",
      "  0.0027383  0.00804953 0.2895752  0.00074149]\n",
      " [0.03030679 0.02441807 0.22968593 0.03752362 0.20505533 0.05168987\n",
      "  0.26339245 0.02078422 0.13028656 0.00685719]\n",
      " [0.01608763 0.01761162 0.01423749 0.5314707  0.0075208  0.05613701\n",
      "  0.00893051 0.07776545 0.26921567 0.00102312]\n",
      " [0.0562476  0.03790736 0.02530104 0.35246438 0.01400623 0.11266165\n",
      "  0.00742584 0.02001391 0.37173095 0.002241  ]\n",
      " [0.0033518  0.08571619 0.02181415 0.05072784 0.10976743 0.05087041\n",
      "  0.02506456 0.41231337 0.22476704 0.01560721]\n",
      " [0.0116844  0.02274573 0.56508046 0.14292245 0.04473795 0.02514714\n",
      "  0.02983082 0.04201918 0.11309523 0.00273671]\n",
      " [0.00114766 0.3194918  0.04616403 0.04900832 0.008976   0.01241196\n",
      "  0.00580015 0.06089542 0.49576914 0.00033557]\n",
      " [0.05375338 0.01875213 0.2535985  0.02255945 0.15758243 0.07279665\n",
      "  0.02984926 0.04698025 0.33375397 0.01037392]\n",
      " [0.01360402 0.00752898 0.09118744 0.03942698 0.44471535 0.04870746\n",
      "  0.03735731 0.05796064 0.22752309 0.03198872]\n",
      " [0.05870044 0.04926217 0.10415763 0.0397918  0.03800309 0.09693827\n",
      "  0.02819737 0.0305627  0.55068916 0.00369734]\n",
      " [0.00434496 0.00655525 0.01236022 0.6823703  0.00854831 0.06327239\n",
      "  0.00093673 0.00401449 0.21746643 0.00013094]\n",
      " [0.08858322 0.0281561  0.04559136 0.21167944 0.17252058 0.05940994\n",
      "  0.08113795 0.12140088 0.16348667 0.02803389]\n",
      " [0.02439435 0.03559526 0.47418395 0.06749663 0.1176949  0.05371554\n",
      "  0.05183314 0.0335387  0.13536368 0.00618382]\n",
      " [0.00267971 0.01903906 0.02387804 0.10141485 0.01365333 0.02475621\n",
      "  0.00453091 0.01512963 0.7945831  0.00033522]\n",
      " [0.00706977 0.01900665 0.0255875  0.08961056 0.3242678  0.0578548\n",
      "  0.02125792 0.1948381  0.2146756  0.04583121]\n",
      " [0.00966863 0.06277241 0.03107584 0.06731062 0.19004846 0.10754243\n",
      "  0.10371128 0.04014311 0.36669955 0.02102759]]\n",
      "train_pred: [3 8 4 4 0 6 3 8 7 2 8 8 4 8 3 3 2 8 4 8]\n",
      "train_true: [9 8 4 9 0 2 3 3 9 2 1 2 9 8 3 7 2 8 9 9]\n",
      "test_pred: [7 2 1 0 4 1 8 8 2 7 0 8 4 0 1 8 4 7 8 4]\n",
      "test_true: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "step   100 train_acc=0.900000 test_acc=0.888700\n",
      "step   200 train_acc=0.980000 test_acc=0.904900\n",
      "step   300 train_acc=0.950000 test_acc=0.907400\n",
      "step   400 train_acc=0.950000 test_acc=0.916100\n",
      "step   500 train_acc=0.990000 test_acc=0.916200\n",
      "step   600 train_acc=0.920000 test_acc=0.912800\n",
      "step   700 train_acc=0.960000 test_acc=0.918400\n",
      "step   800 train_acc=0.910000 test_acc=0.918000\n",
      "step   900 train_acc=0.920000 test_acc=0.914900\n",
      "train_pred_sm: [[0.00005872 0.00509163 0.00717225 0.00116355 0.7354359  0.00554965\n",
      "  0.19512026 0.00748406 0.01837035 0.02455351]\n",
      " [0.00000801 0.00000058 0.00012245 0.00000387 0.99515027 0.0000164\n",
      "  0.00338176 0.00018072 0.00013663 0.00099922]\n",
      " [0.98459333 0.00000006 0.00201391 0.0001092  0.00000236 0.00478493\n",
      "  0.00092825 0.0000005  0.00756298 0.00000453]\n",
      " [0.00159871 0.00000018 0.00004148 0.00009445 0.00000007 0.9966472\n",
      "  0.00001332 0.00000908 0.00156935 0.00002609]\n",
      " [0.0001893  0.00108438 0.03282921 0.00262325 0.00917462 0.01337096\n",
      "  0.00754626 0.00081506 0.9296419  0.00272506]\n",
      " [0.0000917  0.00000037 0.00151497 0.9665849  0.00000354 0.00002757\n",
      "  0.00000061 0.00016774 0.00374015 0.02786822]\n",
      " [0.00002023 0.00002017 0.00006464 0.9940347  0.00001858 0.00546967\n",
      "  0.00005411 0.0000006  0.00030386 0.00001344]\n",
      " [0.00008331 0.00043193 0.00010784 0.00557104 0.00027728 0.96929574\n",
      "  0.00000499 0.00511675 0.01905301 0.00005808]\n",
      " [0.00000037 0.00035367 0.01363998 0.00010462 0.0005144  0.000032\n",
      "  0.974756   0.00000006 0.01059201 0.00000678]\n",
      " [0.00002631 0.         0.00001081 0.00008826 0.00762752 0.00153294\n",
      "  0.00005087 0.00344277 0.00549889 0.98172164]\n",
      " [0.00000328 0.00000005 0.00007218 0.00000206 0.00000142 0.00000208\n",
      "  0.99575377 0.         0.00415595 0.00000917]\n",
      " [0.0000118  0.00000003 0.0001688  0.00000078 0.00000523 0.00003918\n",
      "  0.9994985  0.         0.00027543 0.00000014]\n",
      " [0.00001817 0.9695104  0.0016238  0.01377029 0.00007413 0.00129878\n",
      "  0.00050865 0.00793553 0.00188221 0.00337801]\n",
      " [0.00000294 0.98381835 0.00244232 0.00494163 0.00001189 0.00051571\n",
      "  0.0003673  0.00068178 0.00683373 0.00038445]\n",
      " [0.00004009 0.9578242  0.02187443 0.00442742 0.00001401 0.00035309\n",
      "  0.00017308 0.00010645 0.01510032 0.00008683]\n",
      " [0.00032402 0.00025388 0.00265986 0.00214272 0.00096083 0.00455076\n",
      "  0.9857814  0.00001142 0.00280333 0.00051189]\n",
      " [0.00000169 0.98639214 0.00475908 0.00319632 0.00000542 0.00003901\n",
      "  0.00001839 0.00011735 0.00539211 0.00007841]\n",
      " [0.01249287 0.0000133  0.00000402 0.92266965 0.00002528 0.06110691\n",
      "  0.00003576 0.00002398 0.00348959 0.00013859]\n",
      " [0.99980074 0.         0.00000022 0.00000003 0.         0.00009924\n",
      "  0.00009847 0.         0.00000127 0.        ]\n",
      " [0.00000106 0.00000004 0.9994722  0.00038136 0.00001843 0.00000041\n",
      "  0.00004645 0.00000001 0.00003905 0.00004086]]\n",
      "train_pred: [4 4 0 5 8 3 3 5 6 9 6 6 1 1 1 6 1 3 0 2]\n",
      "train_true: [4 4 0 5 8 3 3 5 6 9 6 6 1 1 1 6 1 3 0 2]\n",
      "test_pred: [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4]\n",
      "test_true: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Process Time(s):0.91\n",
      "0.9192\n"
     ]
    }
   ],
   "source": [
    "### 创建模型----------------------------------\n",
    "\n",
    "# 创建一个占位符x来保存输入值\n",
    "# None表示第一个维度可以是任何长度（输入图片的个数）\n",
    "# 第二个维度784=28x28是每一个图片的展平后的向量\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# 创建一个占位符来保存权重值W和偏置量b\n",
    "# Variable常用来保存参数，计算中可以被修改，初始值为0\n",
    "# 0~9共10个类别\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# y是预测出来的分类结果\n",
    "# x乘以W(相当于W_x)再加上b，然后输入到softmax里面\n",
    "evidence = tf.matmul(x, W) + b\n",
    "y = tf.nn.softmax(evidence)\n",
    "\n",
    "### 计算交叉熵----------------------------------\n",
    "\n",
    "# 创建一个占位符y用来保存输出的正确值（正确分类）\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 计算交叉熵\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    -tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "# cross_entropy = tf.reduce_mean(\n",
    "#     tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y))\n",
    "\n",
    "# 优化方法使用梯度下降算法（gradient descent algorithm）,学习速率为0.5，来最小化交叉熵\n",
    "# 会自动使用反向传播法（backpropagation algorithm）\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "### 训练和评估模型----------------------------------\n",
    "\n",
    "# 建立一个交互式的会话\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# 评估\n",
    "pred = tf.argmax(y, 1)\n",
    "true = tf.argmax(y_, 1)\n",
    "correct_prediction = tf.equal(pred, true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 循环训练1000次\n",
    "# 每次训练会随机抓取训练数据中100个数据点\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    if i % 100 == 0:\n",
    "        train_acc = accuracy.eval(feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        test_acc = accuracy.eval(feed_dict={\n",
    "            x: mnist.test.images,\n",
    "            y_: mnist.test.labels\n",
    "        })\n",
    "        print \"step % 5d\" % (i), \"train_acc={:5f}\".format(\n",
    "            train_acc), \"test_acc={:5f}\".format(test_acc)\n",
    "    if i == 5 or i == 999:\n",
    "        train_pred_sm = y.eval(feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        np.set_printoptions(suppress=True)\n",
    "        print \"train_pred_sm:\", train_pred_sm[:20]\n",
    "        train_pred = pred.eval(feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        train_true = true.eval(feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        test_pred = pred.eval(feed_dict={\n",
    "            x: mnist.test.images,\n",
    "            y_: mnist.test.labels\n",
    "        })\n",
    "        test_true = true.eval(feed_dict={\n",
    "            x: mnist.test.images,\n",
    "            y_: mnist.test.labels\n",
    "        })\n",
    "        print \"train_pred:\", train_pred[:20]\n",
    "        print \"train_true:\", train_true[:20]\n",
    "        print \"test_pred:\", test_pred[:20]\n",
    "        print \"test_true:\", test_true[:20]\n",
    "end = time.time()\n",
    "print \"Process Time(s):{:.2f}\".format(end - start)\n",
    "\n",
    "### 输出结果----------------------------------\n",
    "print(sess.run(\n",
    "    accuracy, feed_dict={\n",
    "        x: mnist.test.images,\n",
    "        y_: mnist.test.labels\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
