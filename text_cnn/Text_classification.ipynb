{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import datetime\n",
    "from text_cnn import TextCNN\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "5331\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n",
      "\n",
      "<class 'list'>\n",
      "5331\n",
      "simplistic , silly and tedious . \n",
      "\n",
      "<class 'list'>\n",
      "10662\n",
      "the rock is destined to be the 21st century 's new conan and that he 's going to make a splash even greater than arnold schwarzenegger , jean claud van damme or steven segal \n",
      "\n",
      "<class 'list'>\n",
      "5331\n",
      "[0, 1] \n",
      "\n",
      "<class 'list'>\n",
      "5331\n",
      "[1, 0] \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "(10662, 2)\n",
      "[0 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "positive_data_file = \"./data/rt-polarity.pos\"\n",
    "negative_data_file = \"./data/rt-polarity.neg\"\n",
    "\n",
    "positive_examples = list(open(positive_data_file, \"r\").readlines())\n",
    "positive_examples = [s.strip() for s in positive_examples]\n",
    "negative_examples = list(open(negative_data_file, \"r\").readlines())\n",
    "negative_examples = [s.strip() for s in negative_examples]\n",
    "\n",
    "print(type(positive_examples))\n",
    "print(len(positive_examples))\n",
    "print(positive_examples[0],\"\\n\")\n",
    "\n",
    "print(type(negative_examples))\n",
    "print(len(negative_examples))\n",
    "print(negative_examples[0],\"\\n\")\n",
    "\n",
    "x_text = positive_examples + negative_examples\n",
    "x_text = [clean_str(sent) for sent in x_text]\n",
    "\n",
    "print(type(x_text))\n",
    "print(len(x_text))\n",
    "print(x_text[0],\"\\n\")\n",
    "\n",
    "positive_labels = [[0, 1] for _ in positive_examples]\n",
    "negative_labels = [[1, 0] for _ in negative_examples]\n",
    "\n",
    "print(type(positive_labels))\n",
    "print(len(positive_labels))\n",
    "print(positive_labels[0],\"\\n\")\n",
    "\n",
    "print(type(negative_labels))\n",
    "print(len(negative_labels))\n",
    "print(negative_labels[0],\"\\n\")\n",
    "\n",
    "y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "print(type(y))\n",
    "print(y.shape)\n",
    "print(y[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 \n",
      "\n",
      "18758 \n",
      "\n",
      "(10662, 56)\n",
      "[ 1  2  3  4  5  6  1  7  8  9 10 11 12 13 14  9 15  5 16 17 18 19 20 21\n",
      " 22 23 24 25 26 27 28 29 30  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0] \n",
      "\n",
      "-1066 \n",
      "\n",
      "(9596, 56)\n",
      "[4719   59  182   34  190  804    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0] \n",
      "\n",
      "(1066, 56)\n",
      "[  292    84   523  1889    99   100   274    67    13 15402   121  4596\n",
      "   600   722  1456  2279   944   207  8493   503   125 10507     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0] \n",
      "\n",
      "(9596, 2)\n",
      "[1 0] \n",
      "\n",
      "(1066, 2)\n",
      "[1 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "print(max_document_length,\"\\n\")\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))\n",
    "print(len(vocab_processor.vocabulary_),\"\\n\")\n",
    "print(x.shape)\n",
    "print(x[0],\"\\n\")\n",
    "\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "dev_sample_percentage = 0.1\n",
    "dev_sample_index = -1 * int(dev_sample_percentage * float(len(y)))\n",
    "print(dev_sample_index,\"\\n\")\n",
    "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train[0],\"\\n\")\n",
    "print(x_dev.shape)\n",
    "print(x_dev[0],\"\\n\")\n",
    "print(y_train.shape)\n",
    "print(y_train[0],\"\\n\")\n",
    "print(y_dev.shape)\n",
    "print(y_dev[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n",
      "step:100\t loss:0.963009\t acc:0.556285\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:200\t loss:0.685209\t acc:0.602251\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:300\t loss:0.642567\t acc:0.629456\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:400\t loss:0.655216\t acc:0.616323\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:500\t loss:0.643114\t acc:0.62758\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:600\t loss:0.663851\t acc:0.616323\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:700\t loss:0.61413\t acc:0.661351\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:800\t loss:0.590864\t acc:0.684803\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:900\t loss:0.58794\t acc:0.682927\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1000\t loss:0.575223\t acc:0.712008\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1100\t loss:0.581421\t acc:0.718574\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1200\t loss:0.574816\t acc:0.724203\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1300\t loss:0.581084\t acc:0.727955\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1400\t loss:0.600231\t acc:0.739212\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1500\t loss:0.612172\t acc:0.745779\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1600\t loss:0.641584\t acc:0.73546\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1700\t loss:0.691855\t acc:0.732645\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1800\t loss:0.719599\t acc:0.73546\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:1900\t loss:0.711525\t acc:0.734522\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2000\t loss:0.755132\t acc:0.73546\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2100\t loss:0.788059\t acc:0.744841\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2200\t loss:0.819007\t acc:0.741088\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2300\t loss:0.852405\t acc:0.738274\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2400\t loss:0.898603\t acc:0.739212\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2500\t loss:0.917433\t acc:0.743902\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2600\t loss:0.969693\t acc:0.736398\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2700\t loss:0.987276\t acc:0.742026\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2800\t loss:1.01504\t acc:0.743902\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:2900\t loss:1.02873\t acc:0.738274\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3000\t loss:1.08063\t acc:0.738274\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3100\t loss:1.09509\t acc:0.744841\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3200\t loss:1.11056\t acc:0.742964\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3300\t loss:1.15205\t acc:0.74015\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3400\t loss:1.15772\t acc:0.738274\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3500\t loss:1.19366\t acc:0.742964\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3600\t loss:1.20652\t acc:0.750469\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3700\t loss:1.22515\t acc:0.746717\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3800\t loss:1.2514\t acc:0.745779\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:3900\t loss:1.27304\t acc:0.745779\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4000\t loss:1.30608\t acc:0.746717\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4100\t loss:1.33133\t acc:0.74015\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4200\t loss:1.3557\t acc:0.741088\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4300\t loss:1.37771\t acc:0.746717\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4400\t loss:1.39984\t acc:0.744841\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4500\t loss:1.42189\t acc:0.750469\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4600\t loss:1.44117\t acc:0.753283\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4700\t loss:1.50784\t acc:0.742026\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4800\t loss:1.50941\t acc:0.741088\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:4900\t loss:1.52725\t acc:0.742026\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5000\t loss:1.55454\t acc:0.736398\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5100\t loss:1.59833\t acc:0.736398\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5200\t loss:1.62054\t acc:0.739212\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5300\t loss:1.65367\t acc:0.736398\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5400\t loss:1.66818\t acc:0.739212\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5500\t loss:1.68431\t acc:0.743902\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5600\t loss:1.70095\t acc:0.742026\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5700\t loss:1.71792\t acc:0.742026\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5800\t loss:1.77059\t acc:0.742026\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:5900\t loss:1.77205\t acc:0.747655\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6000\t loss:1.80866\t acc:0.74015\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6100\t loss:1.83346\t acc:0.743902\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6200\t loss:1.88492\t acc:0.742026\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6300\t loss:1.96681\t acc:0.73546\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6400\t loss:1.97601\t acc:0.741088\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6500\t loss:1.99428\t acc:0.744841\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6600\t loss:2.04509\t acc:0.727955\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6700\t loss:2.03423\t acc:0.742026\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6800\t loss:2.07318\t acc:0.73546\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:6900\t loss:2.09546\t acc:0.742026\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7000\t loss:2.152\t acc:0.738274\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7100\t loss:2.21687\t acc:0.741088\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7200\t loss:2.24574\t acc:0.729831\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7300\t loss:2.2126\t acc:0.744841\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7400\t loss:2.39915\t acc:0.733584\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7500\t loss:2.37863\t acc:0.728893\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7600\t loss:2.40871\t acc:0.728893\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7700\t loss:2.43166\t acc:0.734522\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7800\t loss:2.52812\t acc:0.719512\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:7900\t loss:2.52559\t acc:0.72045\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:8000\t loss:2.57094\t acc:0.729831\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:8100\t loss:2.52383\t acc:0.731707\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:8200\t loss:2.54657\t acc:0.732645\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:8300\t loss:2.63546\t acc:0.730769\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:8400\t loss:2.80861\t acc:0.724203\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "step:8500\t loss:2.67188\t acc:0.74015\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8dd4704b7b90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8dd4704b7b90>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x_batch, y_batch)\u001b[0m\n\u001b[1;32m     39\u001b[0m         }\n\u001b[1;32m     40\u001b[0m         _, step, loss, accuracy = sess.run(\n\u001b[0;32m---> 41\u001b[0;31m             [train_op, global_step, cnn.loss, cnn.accuracy], feed_dict)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m#         print(\"step:{}\\t loss:{:g}\\t acc:{:g}\".format(step, loss,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#                                                   accuracy))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session_conf = tf.ConfigProto(\n",
    "    allow_soft_placement=True, log_device_placement=False)\n",
    "\n",
    "sess = tf.Session(config=session_conf)\n",
    "\n",
    "embedding_dim = 128\n",
    "filter_sizes = \"3,4,5\"\n",
    "num_filters = 128\n",
    "l2_reg_lambda = 0.0\n",
    "dropout_keep_prob = 0.5\n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "evaluate_every = 100\n",
    "checkpoint_every = 100\n",
    "\n",
    "with sess.as_default():\n",
    "    cnn = TextCNN(\n",
    "        sequence_length=x_train.shape[1],\n",
    "        num_classes=y_train.shape[1],\n",
    "        vocab_size=len(vocab_processor.vocabulary_),\n",
    "        embedding_size=embedding_dim,\n",
    "        filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
    "        num_filters=num_filters,\n",
    "        l2_reg_lambda=l2_reg_lambda)\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "    grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        grads_and_vars, global_step=global_step)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def train_step(x_batch, y_batch):\n",
    "        feed_dict = {\n",
    "            cnn.input_x: x_batch,\n",
    "            cnn.input_y: y_batch,\n",
    "            cnn.dropout_keep_prob: dropout_keep_prob\n",
    "        }\n",
    "        _, step, loss, accuracy = sess.run(\n",
    "            [train_op, global_step, cnn.loss, cnn.accuracy], feed_dict)\n",
    "#         print(\"step:{}\\t loss:{:g}\\t acc:{:g}\".format(step, loss,\n",
    "#                                                   accuracy))\n",
    "\n",
    "    def dev_step(x_batch, y_batch):\n",
    "        feed_dict = {\n",
    "            cnn.input_x: x_batch,\n",
    "            cnn.input_y: y_batch,\n",
    "            cnn.dropout_keep_prob: 1.0\n",
    "        }\n",
    "        step, loss, accuracy = sess.run([global_step, cnn.loss, cnn.accuracy],\n",
    "                                        feed_dict)\n",
    "        print(\"step:{}\\t loss:{:g}\\t acc:{:g}\".format(step, loss, accuracy))\n",
    "        \n",
    "    batches = batch_iter(list(zip(x_train, y_train)), batch_size, num_epochs)\n",
    "    \n",
    "    \n",
    "    for batch in batches:\n",
    "        x_batch, y_batch = zip(*batch)\n",
    "        train_step(x_batch, y_batch)\n",
    "        current_step = tf.train.global_step(sess, global_step)\n",
    "        if current_step % evaluate_every == 0:\n",
    "            print(\"\\nEvaluation:\")\n",
    "            dev_step(x_dev, y_dev)\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
