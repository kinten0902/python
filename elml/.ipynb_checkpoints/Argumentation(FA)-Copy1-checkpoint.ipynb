{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 処理の流れを理解するために整理するipynb\n",
    "\n",
    "## このipynbの目標\n",
    "- Argumentationに着目して細かい検証をする\n",
    "    - 人A\n",
    "    - 人B\n",
    "    - 人一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:21.553264Z",
     "start_time": "2017-12-07T08:46:21.542115Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import mojimoji\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import MeCab\n",
    "import types\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "\n",
    "mc = MeCab.Tagger(\"-Ochasen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:21.673690Z",
     "start_time": "2017-12-07T08:46:21.554332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m171116_old.xlsx\u001b[0m*        \u001b[01;32mA_W_171116.xlsx\u001b[0m*      \u001b[01;32mREADME.md\u001b[0m*\r\n",
      "\u001b[01;32m171116.xlsx\u001b[0m*            \u001b[01;32mA_W_171121.xlsx\u001b[0m*      \u001b[01;32mSimpleData.xlsx\u001b[0m*\r\n",
      "\u001b[01;32m2015斉藤.xlsx\u001b[0m*          \u001b[01;32mA_W_171128_old.xlsx\u001b[0m*\r\n",
      "\u001b[01;32m20171031結果7-10.xlsx\u001b[0m*  \u001b[01;32mA_W_171128.xlsx\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls data/excel/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T13:43:49.197685Z",
     "start_time": "2017-11-24T13:43:48.638408Z"
    }
   },
   "source": [
    "# Excelのdata_frame化\n",
    "- 現状開かれるファイル\n",
    "    - A_W_171116\n",
    "        - excelの行番号1～299行目までのデータを使用\n",
    "    - A_W_171121\n",
    "        - excelの行番号300～末尾行目までのデータを使用\n",
    "    - S_H_171116\n",
    "        - A_W_YYMMDDとは別の人たちが作成したexcelデータ\n",
    "    - 斎藤_2015\n",
    "        - S_H_1116の破損しているreply列のデータを修復するためのファイル\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:22.729898Z",
     "start_time": "2017-12-07T08:46:21.677390Z"
    }
   },
   "outputs": [],
   "source": [
    "dirpath = \"data/excel/\"\n",
    "filename = \"A_W_171116.xlsx\"\n",
    "A_W_171116_excel = pd.ExcelFile(dirpath + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:22.827604Z",
     "start_time": "2017-12-07T08:46:22.731124Z"
    }
   },
   "outputs": [],
   "source": [
    "sheet_name = A_W_171116_excel.sheet_names[0]\n",
    "A_W_171116_df = A_W_171116_excel.parse(sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:24.373679Z",
     "start_time": "2017-12-07T08:46:22.828857Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"A_W_171128.xlsx\"\n",
    "A_W_171128_excel = pd.ExcelFile(dirpath + filename)\n",
    "sheet_name = A_W_171128_excel.sheet_names[0]\n",
    "A_W_171128_df = A_W_171128_excel.parse(sheet_name)\n",
    "\n",
    "# A_W_171128_df = A_W_171128_df[:3499]\n",
    "# A_W_171128_df[::-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.305409Z",
     "start_time": "2017-12-07T08:46:24.374929Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"171116.xlsx\"\n",
    "S_H_171116_excel = pd.ExcelFile(dirpath + filename)\n",
    "sheet_name = S_H_171116_excel.sheet_names[0]\n",
    "S_H_171116_df = S_H_171116_excel.parse(sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.805222Z",
     "start_time": "2017-12-07T08:46:25.306657Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"2015斉藤.xlsx\"\n",
    "S_2015_excel = pd.ExcelFile(dirpath + filename)\n",
    "sheet_name = S_2015_excel.sheet_names[0]\n",
    "S_2015_df = S_2015_excel.parse(sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.815372Z",
     "start_time": "2017-12-07T08:46:25.806522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 No. No.\n",
      "1 返信元 返信元\n",
      "2 発言の起点 発言の起点\n",
      "3 起点からの数 起点からの数\n",
      "4 時間 時間\n",
      "5 lid lid\n",
      "6 gid gid\n",
      "7 発言者ID 発言者ID\n",
      "8 ニックネーム ニックネーム\n",
      "9 宛先者ID 宛先者ID\n",
      "10 宛先 宛先\n",
      "11 発言内容 発言内容\n",
      "12 Epistemic Epistemic(A)\n",
      "13 Watanabe Watanabe\n",
      "14 Unnamed: 14 Unnamed: 14\n",
      "15 ○× ○×\n",
      "16 ? ?\n",
      "17 Coordination Coordination(A)\n",
      "18 Watanabe.1 Watanabe.1\n",
      "19 Unnamed: 19 Unnamed: 19\n",
      "20 ○×.1 ○×.1\n",
      "21 ?2 ?2\n",
      "22 Argumentation Argumentation(A)\n",
      "23 Watanabe.2 Watanabe.2\n",
      "24 Unnamed: 24 Unnamed: 24\n",
      "25 ○×.2 ○×.2\n",
      "26 ?3 ?3\n",
      "27 Social Social(A)\n",
      "28 Watanabe.3 Watanabe.3\n",
      "29 Unnamed: 29 Unnamed: 29\n",
      "30 ○×.3 ○×.3\n",
      "31 ?4 ?4\n",
      "32 Target Target(A)\n",
      "33 Watanabe.4 Watanabe.4\n",
      "34 Unnamed: 34 Unnamed: 34\n",
      "35 ?5 ?5\n"
     ]
    }
   ],
   "source": [
    "for i ,(columns1116, columns1128) in enumerate(zip(A_W_171116_df, A_W_171128_df)):\n",
    "    print(i, columns1116, columns1128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.836085Z",
     "start_time": "2017-12-07T08:46:25.816537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>返信元</th>\n",
       "      <th>発言の起点</th>\n",
       "      <th>起点からの数</th>\n",
       "      <th>時間</th>\n",
       "      <th>lid</th>\n",
       "      <th>gid</th>\n",
       "      <th>発言者ID</th>\n",
       "      <th>ニックネーム</th>\n",
       "      <th>宛先者ID</th>\n",
       "      <th>...</th>\n",
       "      <th>?3</th>\n",
       "      <th>Social(A)</th>\n",
       "      <th>Watanabe.3</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>○×.3</th>\n",
       "      <th>?4</th>\n",
       "      <th>Target(A)</th>\n",
       "      <th>Watanabe.4</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>?5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-06-16 16:05:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-06-16 16:06:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>哲</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-06-16 16:06:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    No. 返信元  発言の起点  起点からの数                  時間  lid  gid  発言者ID ニックネーム  宛先者ID  \\\n",
       "0   1.0  \\N    1.0     0.0 2015-06-16 16:05:00  1.0  1.0   52.0   まこぴす    0.0   \n",
       "1  31.0  \\N   31.0     0.0 2015-06-16 16:06:00  1.0  1.0  147.0      哲    0.0   \n",
       "2  70.0  \\N   70.0     0.0 2015-06-16 16:06:00  1.0  1.0    8.0     仙波    0.0   \n",
       "\n",
       "  ...  ?3 Social(A) Watanabe.3 Unnamed: 29 ○×.3  ?4  Target(A) Watanabe.4  \\\n",
       "0 ... NaN       NaN        NaN           0  1.0 NaN        NaN        NaN   \n",
       "1 ... NaN       NaN        NaN           0  1.0 NaN        NaN        NaN   \n",
       "2 ... NaN       NaN        NaN           0  1.0 NaN        NaN        NaN   \n",
       "\n",
       "  Unnamed: 34  ?5  \n",
       "0         NaN NaN  \n",
       "1         NaN NaN  \n",
       "2         NaN NaN  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_W_171128_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.842624Z",
     "start_time": "2017-12-07T08:46:25.837179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 id\n",
      "1 date\n",
      "2 列1\n",
      "3 reply\n",
      "4 lid\n",
      "5 gid\n",
      "6 cname\n",
      "7 label\n",
      "8 body\n",
      "9 Epistemic(H)\n",
      "10 Epistemic(S)\n",
      "11 Epistemic(FA)\n",
      "12 ?(2)\n",
      "13 Coordination(H)\n",
      "14 Coordination(S)\n",
      "15 Coordination(FA)\n",
      "16 ?(2-2)\n",
      "17 Argumentation(H)\n",
      "18 Argumentation(S)\n",
      "19 Argumentation(FA)\n",
      "20 ?(3)\n",
      "21 Social(H)\n",
      "22 Social(S)\n",
      "23 Social(FA)\n",
      "24 ?(5)\n",
      "25 Social Target\n",
      "26 ?(ST)\n",
      "27 Unnamed: 27\n",
      "28 Unnamed: 28\n",
      "29 Unnamed: 29\n"
     ]
    }
   ],
   "source": [
    "for i, columns in enumerate(S_H_171116_df):\n",
    "    print(i, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.852665Z",
     "start_time": "2017-12-07T08:46:25.843546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>発言番号</th>\n",
       "      <th>返信元</th>\n",
       "      <th>発言の起点</th>\n",
       "      <th>起点からの数</th>\n",
       "      <th>時間</th>\n",
       "      <th>講義番号</th>\n",
       "      <th>グループ番号</th>\n",
       "      <th>発言者ID</th>\n",
       "      <th>ニックネーム</th>\n",
       "      <th>宛先者ID</th>\n",
       "      <th>宛先</th>\n",
       "      <th>発言内容</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1593</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-21 06:19:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>世界のわたべ</td>\n",
       "      <td>0</td>\n",
       "      <td>全員</td>\n",
       "      <td>よろしくお願いします。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1598</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1598</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-21 06:20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ざきさん</td>\n",
       "      <td>0</td>\n",
       "      <td>全員</td>\n",
       "      <td>よろしくです</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1606</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1606</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-21 06:20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>あ</td>\n",
       "      <td>0</td>\n",
       "      <td>全員</td>\n",
       "      <td>よろしくです</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   発言番号 返信元  発言の起点  起点からの数                  時間  講義番号  グループ番号  発言者ID  ニックネーム  \\\n",
       "0  1593  \\N   1593       0 2015-07-21 06:19:00     2       1      2  世界のわたべ   \n",
       "1  1598  \\N   1598       0 2015-07-21 06:20:00     2       1      3    ざきさん   \n",
       "2  1606  \\N   1606       0 2015-07-21 06:20:00     2       1     56       あ   \n",
       "\n",
       "   宛先者ID  宛先         発言内容  \n",
       "0      0  全員  よろしくお願いします。  \n",
       "1      0  全員       よろしくです  \n",
       "2      0  全員       よろしくです  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_2015_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.856505Z",
     "start_time": "2017-12-07T08:46:25.853547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, '\\\\N', 1, 0, Timestamp('2015-06-16 16:05:00'), 1, 1, 52,\n",
       "        'まこぴす', 0, '全員', 'よろしくお願いします！', 'Off task', 'Off Task',\n",
       "        'Off task', 1, nan, nan, nan, nan, 1.0, nan,\n",
       "        'Non-argumentative moves', 'Non-argumentative moves',\n",
       "        'Non-argumentative moves', 1.0, nan, nan, nan, nan, 1.0, nan,\n",
       "        nan, nan, nan, nan],\n",
       "       [31, '\\\\N', 31, 0, Timestamp('2015-06-16 16:06:00'), 1, 1, 147,\n",
       "        '哲', 0, '全員', 'よろしくお願いします', 'Off task', 'Off Task', 'Off task',\n",
       "        1, nan, nan, nan, nan, 1.0, nan, 'Non-argumentative moves',\n",
       "        'Non-argumentative moves', 'Non-argumentative moves', 1.0, nan,\n",
       "        nan, nan, nan, 1.0, nan, nan, nan, nan, nan],\n",
       "       [70, '\\\\N', 70, 0, Timestamp('2015-06-16 16:06:00'), 1, 1, 8,\n",
       "        '仙波', 0, '全員', '名前なのが恥ずかしいです…\\n\\nよろしくお願いします！', 'Off task',\n",
       "        'Off Task', 'Off task', 1, nan, nan, nan, nan, 1.0, nan,\n",
       "        'Non-argumentative moves', 'Non-argumentative moves',\n",
       "        'Non-argumentative moves', 1.0, nan, nan, nan, nan, 1.0, nan,\n",
       "        nan, nan, nan, nan]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_W_171116_df.head(3).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T14:50:49.806719Z",
     "start_time": "2017-11-24T14:50:49.798361Z"
    }
   },
   "source": [
    "## 必要なデータ\n",
    "- id\n",
    "    - A_W_YYMMDDのNo.(0列目)\n",
    "    - SH_171116のid(0列目)\n",
    "    - 斉藤2015の発言番号(0列目)\n",
    "- reply\n",
    "    - A_W_YYMMDDの返信元(1列目)\n",
    "    - SH_171116のreply(3列目)\n",
    "    - 斉藤2015の返信元(1列目)\n",
    "- group\n",
    "    - A_W_YYMMDDのgid(6列目)\n",
    "    - SH_171116のgid(5列目)\n",
    "    - 斉藤2015のグループ番号(6列目)\n",
    "- who\n",
    "    - A_W_YYMMDDのニックネーム(8列目)\n",
    "    - SH_171116のcname(6列目)\n",
    "    - 斉藤2015のニックネーム(8列目)\n",
    "- body\n",
    "    - A_W_YYMMDDの発言内容(11列目)\n",
    "    - SH_171116のbody(8列目)\n",
    "    - 斉藤2015の発言内容(11列目)\n",
    "- argumentation_a\n",
    "    - A_W_YYMMDDのArgumentation(A)(22列目)\n",
    "    - SH_171116のArgumentation(H)(17列目)\n",
    "- argumentation_b\n",
    "    - A_W_YYMMDDのWatanabe.2(23列目)\n",
    "    - SH_171116のArgumentation(S)(18列目)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各dfで必要な列\n",
    "- A_W_YYMMDD[0, 1, 6, 8, 11, 22, 23]\n",
    "- SH_171116[0, 3, 5, 6, 8, 17, 18]\n",
    "- 斉藤2015[0, 1, 6, 8, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.861832Z",
     "start_time": "2017-12-07T08:46:25.857398Z"
    }
   },
   "outputs": [],
   "source": [
    "A_W_YYMMDD_use = [0, 1, 6, 8, 11, 22, 23]\n",
    "S_H_171116_use = [0, 3, 5, 6, 8, 17, 18]\n",
    "S_2015_use = [0, 1, 6, 8, 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T15:34:53.985683Z",
     "start_time": "2017-11-24T15:34:53.981944Z"
    }
   },
   "source": [
    "## 使用しない列の削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.866523Z",
     "start_time": "2017-12-07T08:46:25.862743Z"
    }
   },
   "outputs": [],
   "source": [
    "# A_W_YYMMDDの列名の統合\n",
    "A_W_171116_df.columns = A_W_171128_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.872000Z",
     "start_time": "2017-12-07T08:46:25.867419Z"
    }
   },
   "outputs": [],
   "source": [
    "delete_columns_list = []\n",
    "for i, column in enumerate(A_W_171116_df):\n",
    "    if not i in A_W_YYMMDD_use:\n",
    "        delete_columns_list.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.878293Z",
     "start_time": "2017-12-07T08:46:25.872992Z"
    }
   },
   "outputs": [],
   "source": [
    "A_W_171116_df = A_W_171116_df.drop(delete_columns_list, axis=1)\n",
    "A_W_171128_df = A_W_171128_df.drop(delete_columns_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.882712Z",
     "start_time": "2017-12-07T08:46:25.879256Z"
    }
   },
   "outputs": [],
   "source": [
    "delete_columns_list = []\n",
    "for i, column in enumerate(S_H_171116_df):\n",
    "    if not i in S_H_171116_use:\n",
    "        delete_columns_list.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.888596Z",
     "start_time": "2017-12-07T08:46:25.883691Z"
    }
   },
   "outputs": [],
   "source": [
    "S_H_171116_df = S_H_171116_df.drop(delete_columns_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.895063Z",
     "start_time": "2017-12-07T08:46:25.889632Z"
    }
   },
   "outputs": [],
   "source": [
    "delete_columns_list = []\n",
    "for i, column in enumerate(S_2015_df):\n",
    "    if not i in S_2015_use:\n",
    "        delete_columns_list.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.900353Z",
     "start_time": "2017-12-07T08:46:25.895933Z"
    }
   },
   "outputs": [],
   "source": [
    "S_2015_df = S_2015_df.drop(delete_columns_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.911182Z",
     "start_time": "2017-12-07T08:46:25.901353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>返信元</th>\n",
       "      <th>gid</th>\n",
       "      <th>ニックネーム</th>\n",
       "      <th>発言内容</th>\n",
       "      <th>Argumentation(A)</th>\n",
       "      <th>Watanabe.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>よろしくお願いします！</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>哲</td>\n",
       "      <td>よろしくお願いします</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>仙波</td>\n",
       "      <td>名前なのが恥ずかしいです…\\n\\nよろしくお願いします！</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No. 返信元  gid ニックネーム                          発言内容         Argumentation(A)  \\\n",
       "0    1  \\N    1   まこぴす                   よろしくお願いします！  Non-argumentative moves   \n",
       "1   31  \\N    1      哲                    よろしくお願いします  Non-argumentative moves   \n",
       "2   70  \\N    1     仙波  名前なのが恥ずかしいです…\\n\\nよろしくお願いします！  Non-argumentative moves   \n",
       "\n",
       "                Watanabe.2  \n",
       "0  Non-argumentative moves  \n",
       "1  Non-argumentative moves  \n",
       "2  Non-argumentative moves  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_W_171116_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.919886Z",
     "start_time": "2017-12-07T08:46:25.912118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>返信元</th>\n",
       "      <th>gid</th>\n",
       "      <th>ニックネーム</th>\n",
       "      <th>発言内容</th>\n",
       "      <th>Argumentation(A)</th>\n",
       "      <th>Watanabe.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>よろしくお願いします！</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>哲</td>\n",
       "      <td>よろしくお願いします</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>名前なのが恥ずかしいです…\\n\\nよろしくお願いします！</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    No. 返信元  gid ニックネーム                          発言内容  \\\n",
       "0   1.0  \\N  1.0   まこぴす                   よろしくお願いします！   \n",
       "1  31.0  \\N  1.0      哲                    よろしくお願いします   \n",
       "2  70.0  \\N  1.0     仙波  名前なのが恥ずかしいです…\\n\\nよろしくお願いします！   \n",
       "\n",
       "          Argumentation(A)               Watanabe.2  \n",
       "0  Non-argumentative moves  Non-argumentative moves  \n",
       "1  Non-argumentative moves  Non-argumentative moves  \n",
       "2  Non-argumentative moves  Non-argumentative moves  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_W_171128_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.927875Z",
     "start_time": "2017-12-07T08:46:25.920800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reply</th>\n",
       "      <th>gid</th>\n",
       "      <th>cname</th>\n",
       "      <th>body</th>\n",
       "      <th>Argumentation(H)</th>\n",
       "      <th>Argumentation(S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>世界のわたべ</td>\n",
       "      <td>よろしくお願いします。</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1598</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>ざきさん</td>\n",
       "      <td>よろしくです</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1606</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>あ</td>\n",
       "      <td>よろしくです</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  reply  gid   cname         body         Argumentation(H)  \\\n",
       "0  1593      2    2  世界のわたべ  よろしくお願いします。  Non-argumentative moves   \n",
       "1  1598      2    3    ざきさん       よろしくです  Non-argumentative moves   \n",
       "2  1606      2   56       あ       よろしくです  Non-argumentative moves   \n",
       "\n",
       "          Argumentation(S)  \n",
       "0  Non-argumentative moves  \n",
       "1  Non-argumentative moves  \n",
       "2  Non-argumentative moves  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_H_171116_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.934880Z",
     "start_time": "2017-12-07T08:46:25.928768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>発言番号</th>\n",
       "      <th>返信元</th>\n",
       "      <th>グループ番号</th>\n",
       "      <th>ニックネーム</th>\n",
       "      <th>発言内容</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>世界のわたべ</td>\n",
       "      <td>よろしくお願いします。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1598</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>ざきさん</td>\n",
       "      <td>よろしくです</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1606</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>あ</td>\n",
       "      <td>よろしくです</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   発言番号 返信元  グループ番号  ニックネーム         発言内容\n",
       "0  1593  \\N       1  世界のわたべ  よろしくお願いします。\n",
       "1  1598  \\N       1    ざきさん       よろしくです\n",
       "2  1606  \\N       1       あ       よろしくです"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_2015_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの一致の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.939282Z",
     "start_time": "2017-12-07T08:46:25.935775Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(not False in S_H_171116_df['id'].values == S_2015_df['発言番号'].values)\n",
    "print(not False in S_H_171116_df['cname'].values == S_2015_df['ニックネーム'].values)\n",
    "print(not False in S_H_171116_df['body'].values == S_2015_df['発言内容'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 欠損データの置換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.944898Z",
     "start_time": "2017-12-07T08:46:25.940280Z"
    }
   },
   "outputs": [],
   "source": [
    "S_H_171116_df[\"reply\"] = S_2015_df['返信元']\n",
    "S_H_171116_df[\"gid\"] = S_2015_df['グループ番号']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.955159Z",
     "start_time": "2017-12-07T08:46:25.946015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reply</th>\n",
       "      <th>gid</th>\n",
       "      <th>cname</th>\n",
       "      <th>body</th>\n",
       "      <th>Argumentation(H)</th>\n",
       "      <th>Argumentation(S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>世界のわたべ</td>\n",
       "      <td>よろしくお願いします。</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1598</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>ざきさん</td>\n",
       "      <td>よろしくです</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1606</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>あ</td>\n",
       "      <td>よろしくです</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id reply  gid   cname         body         Argumentation(H)  \\\n",
       "0  1593    \\N    1  世界のわたべ  よろしくお願いします。  Non-argumentative moves   \n",
       "1  1598    \\N    1    ざきさん       よろしくです  Non-argumentative moves   \n",
       "2  1606    \\N    1       あ       よろしくです  Non-argumentative moves   \n",
       "\n",
       "          Argumentation(S)  \n",
       "0  Non-argumentative moves  \n",
       "1  Non-argumentative moves  \n",
       "2  Non-argumentative moves  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_H_171116_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A_W_YYMMDDの結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.960723Z",
     "start_time": "2017-12-07T08:46:25.956230Z"
    }
   },
   "outputs": [],
   "source": [
    "concat_border = 299\n",
    "A_W_171116_df = A_W_171116_df[0:concat_border]\n",
    "A_W_171128_df = A_W_171128_df[concat_border:]\n",
    "A_W_df = pd.concat([A_W_171116_df, A_W_171128_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.971564Z",
     "start_time": "2017-12-07T08:46:25.961670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>返信元</th>\n",
       "      <th>gid</th>\n",
       "      <th>ニックネーム</th>\n",
       "      <th>発言内容</th>\n",
       "      <th>Argumentation(A)</th>\n",
       "      <th>Watanabe.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>816.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100g188円</td>\n",
       "      <td>いま見てみたら割ときてましたｗ</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Simple Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>876.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100g188円</td>\n",
       "      <td>ムードルだとこないのコンテンツ工程くらいでしたか</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Simple Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1083.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Loki</td>\n",
       "      <td>とりあえず共有テキストに書いてみた\\n\\nスマートフォンの場合が使ったことないから分からない…</td>\n",
       "      <td>Simple claim</td>\n",
       "      <td>Simple Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1139.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100g188円</td>\n",
       "      <td>スマフォではうちも使ったことないですねぇ・・・</td>\n",
       "      <td>Simple claim</td>\n",
       "      <td>Simple Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1277.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100g188円</td>\n",
       "      <td>PCつかえてればスマフォで使おうとはおもあないですよね～</td>\n",
       "      <td>Grounded claim</td>\n",
       "      <td>Qualified Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1310.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100g188円</td>\n",
       "      <td>思わ</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Simple Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1324.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Loki</td>\n",
       "      <td>とりあえず今書いてあることを回答に書きますか</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1370.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Loki</td>\n",
       "      <td>先に書いてもらいありがとうございます～</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1393.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100g188円</td>\n",
       "      <td>(＾　＾)＞</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>24.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>12.0</td>\n",
       "      <td>ざきさん</td>\n",
       "      <td>よろしくお願いします</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "      <td>Non-argumentative moves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        No. 返信元   gid    ニックネーム  \\\n",
       "295   816.0  \\N  11.0  100g188円   \n",
       "296   876.0  \\N  11.0  100g188円   \n",
       "297  1083.0  \\N  11.0      Loki   \n",
       "298  1139.0  \\N  11.0  100g188円   \n",
       "299  1277.0  \\N  11.0  100g188円   \n",
       "300  1310.0  \\N  11.0  100g188円   \n",
       "301  1324.0  \\N  11.0      Loki   \n",
       "302  1370.0  \\N  11.0      Loki   \n",
       "303  1393.0  \\N  11.0  100g188円   \n",
       "304    24.0  \\N  12.0      ざきさん   \n",
       "\n",
       "                                                発言内容         Argumentation(A)  \\\n",
       "295                                  いま見てみたら割ときてましたｗ  Non-argumentative moves   \n",
       "296                         ムードルだとこないのコンテンツ工程くらいでしたか  Non-argumentative moves   \n",
       "297  とりあえず共有テキストに書いてみた\\n\\nスマートフォンの場合が使ったことないから分からない…             Simple claim   \n",
       "298                          スマフォではうちも使ったことないですねぇ・・・             Simple claim   \n",
       "299                     PCつかえてればスマフォで使おうとはおもあないですよね～           Grounded claim   \n",
       "300                                               思わ  Non-argumentative moves   \n",
       "301                           とりあえず今書いてあることを回答に書きますか  Non-argumentative moves   \n",
       "302                              先に書いてもらいありがとうございます～  Non-argumentative moves   \n",
       "303                                           (＾　＾)＞  Non-argumentative moves   \n",
       "304                                       よろしくお願いします  Non-argumentative moves   \n",
       "\n",
       "                  Watanabe.2  \n",
       "295             Simple Claim  \n",
       "296             Simple Claim  \n",
       "297             Simple Claim  \n",
       "298             Simple Claim  \n",
       "299          Qualified Claim  \n",
       "300             Simple Claim  \n",
       "301  Non-argumentative moves  \n",
       "302  Non-argumentative moves  \n",
       "303  Non-argumentative moves  \n",
       "304  Non-argumentative moves  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_W_df[295:305]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用できないレベルの欠損値のある行を取り除く\n",
    "- どこに基準を置くかは要検討\n",
    "- とりあえずは、人間が個人作業で付けたラベルのみNanを取り除く\n",
    "    - ~~ArgumentationのNanを弾くと、No Senseが全部消える…~~\n",
    "        - ~~No Senseの内訳はほとんど連投と一部の意味不明発言だけだから今回の分類対象から外したい？~~\n",
    "        - ~~(On Offに絞るとArgumentation含めた前処理が楽になりそう)~~\n",
    "    - ArgumentationはNo Senseにも付くから問題なさそう？\n",
    "    - 両方の人がNo Senseの時はArgumentationついていないけど、片方がNo Senseの時は両方にArgumentationついている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.978025Z",
     "start_time": "2017-12-07T08:46:25.972451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No.                   3\n",
       "返信元                   3\n",
       "gid                   3\n",
       "ニックネーム                3\n",
       "発言内容                  3\n",
       "Argumentation(A)    113\n",
       "Watanabe.2          212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要素含まれるNanの数を確認\n",
    "A_W_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.985273Z",
     "start_time": "2017-12-07T08:46:25.979053Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No.                 False\n",
       "返信元                 False\n",
       "gid                 False\n",
       "ニックネーム              False\n",
       "発言内容                False\n",
       "Argumentation(A)    False\n",
       "Watanabe.2          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A_W_dfの人間が付けたラベル列のNanを取り除く\n",
    "A_W_df = A_W_df.dropna(subset=['Argumentation(A)', 'Watanabe.2'])\n",
    "# 要素にNanが含まれる列を再確認\n",
    "A_W_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.990500Z",
     "start_time": "2017-12-07T08:46:25.986123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "reply                 0\n",
       "gid                   0\n",
       "cname                 0\n",
       "body                  0\n",
       "Argumentation(H)    189\n",
       "Argumentation(S)    225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 要素に含まれるNanの数を確認\n",
    "S_H_171116_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:25.997828Z",
     "start_time": "2017-12-07T08:46:25.991405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  False\n",
       "reply               False\n",
       "gid                 False\n",
       "cname               False\n",
       "body                False\n",
       "Argumentation(H)    False\n",
       "Argumentation(S)    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S_H_171116_dfの人間が付けたラベル列のNanを取り除く\n",
    "S_H_171116_df = S_H_171116_df.dropna(subset=['Argumentation(H)', 'Argumentation(S)'])\n",
    "# 要素にNanが含まれる列を再確認\n",
    "S_H_171116_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重複投稿の排除\n",
    "- 発言者と発言内容が重複している行を排除する\n",
    "- これだと連投だけでなく、「よろしくお願いします」などの定型的な発言がスキップされてしまう\n",
    "- 他の人の投稿を挟んでの連投を排除できる\n",
    "- 「よろしくお願いいたします」などの定型文はoff task\n",
    "- 文の前後関係においてもノイズになりやすそう(よろしくお願いしますから発生する次の発言は多様すぎて関連性が薄いと思いたい)\n",
    "- **元データのラベル付けルールの整合性とかがかなり怪しいから荒っぽい前処理くらい許して欲しい**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.002084Z",
     "start_time": "2017-12-07T08:46:25.998695Z"
    }
   },
   "outputs": [],
   "source": [
    "A_W_df = A_W_df.drop_duplicates(subset=['ニックネーム', '発言内容'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.008918Z",
     "start_time": "2017-12-07T08:46:26.003084Z"
    }
   },
   "outputs": [],
   "source": [
    "S_H_171116_df = S_H_171116_df.drop_duplicates(subset=['cname', 'body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラベルの表記ゆれの修正\n",
    "ラベルを小文字に統一する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epistemicの修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.070123Z",
     "start_time": "2017-12-07T08:46:26.010080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'non-argumentative moves': 2566, 'simple claim': 1484, 'grounded claim': 281, 'qualified claim': 67, 'grounded and qualified claim': 15})\n",
      "Counter({'non-argumentative moves': 2459, 'simple claim': 1683, 'grounded claim': 221, 'qualified claim': 43, 'grounded and qualified claim': 7})\n"
     ]
    }
   ],
   "source": [
    "# 表記ゆれの修正と確認\n",
    "A_W_df['Argumentation(A)'] = A_W_df['Argumentation(A)'].str.lower()\n",
    "counter = Counter(A_W_df['Argumentation(A)'])\n",
    "print(counter)\n",
    "A_W_df['Watanabe.2'] = A_W_df['Watanabe.2'].str.lower()\n",
    "counter = Counter(A_W_df['Watanabe.2'])\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.124527Z",
     "start_time": "2017-12-07T08:46:26.071206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'non-argumentative moves': 2765, 'simple claim': 1730, 'grounded claim': 150, 'qualified claim': 18, 'grounded and qualified claim': 7})\n",
      "Counter({'non-argumentative moves': 2814, 'simple claim': 1597, 'grounded claim': 200, 'qualified claim': 51, 'grounded and qualified claim': 8})\n"
     ]
    }
   ],
   "source": [
    "# 表記ゆれの確認\n",
    "S_H_171116_df['Argumentation(S)'] = S_H_171116_df['Argumentation(S)'].str.lower()\n",
    "counter = Counter(S_H_171116_df['Argumentation(S)'])\n",
    "print(counter)\n",
    "S_H_171116_df['Argumentation(H)'] = S_H_171116_df['Argumentation(H)'].str.lower()\n",
    "counter = Counter(S_H_171116_df['Argumentation(H)'])\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相談なしで一致しているラベルの抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一致しているArgumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.139962Z",
     "start_time": "2017-12-07T08:46:26.125892Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>返信元</th>\n",
       "      <th>gid</th>\n",
       "      <th>ニックネーム</th>\n",
       "      <th>発言内容</th>\n",
       "      <th>Argumentation(A)</th>\n",
       "      <th>Watanabe.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>よろしくお願いします！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>哲</td>\n",
       "      <td>よろしくお願いします</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>名前なのが恥ずかしいです…\\n\\nよろしくお願いします！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>早速課題やっちゃいましょう！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>やっちゃいましょう\\n\\nmoodleはゴミです！</td>\n",
       "      <td>simple claim</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     No. 返信元  gid ニックネーム                          発言内容  \\\n",
       "0    1.0  \\N  1.0   まこぴす                   よろしくお願いします！   \n",
       "1   31.0  \\N  1.0      哲                    よろしくお願いします   \n",
       "2   70.0  \\N  1.0     仙波  名前なのが恥ずかしいです…\\n\\nよろしくお願いします！   \n",
       "3  119.0  \\N  1.0   まこぴす                早速課題やっちゃいましょう！   \n",
       "4  163.0  \\N  1.0     仙波     やっちゃいましょう\\n\\nmoodleはゴミです！   \n",
       "\n",
       "          Argumentation(A)               Watanabe.2  \n",
       "0  non-argumentative moves  non-argumentative moves  \n",
       "1  non-argumentative moves  non-argumentative moves  \n",
       "2  non-argumentative moves  non-argumentative moves  \n",
       "3  non-argumentative moves  non-argumentative moves  \n",
       "4             simple claim             simple claim  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_W_match_df = A_W_df[A_W_df['Argumentation(A)'] == A_W_df['Watanabe.2']].reset_index(drop=True)\n",
    "A_W_match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.152111Z",
     "start_time": "2017-12-07T08:46:26.141346Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reply</th>\n",
       "      <th>gid</th>\n",
       "      <th>cname</th>\n",
       "      <th>body</th>\n",
       "      <th>Argumentation(H)</th>\n",
       "      <th>Argumentation(S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>世界のわたべ</td>\n",
       "      <td>よろしくお願いします。</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1598</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>ざきさん</td>\n",
       "      <td>よろしくです</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1606</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>あ</td>\n",
       "      <td>よろしくです</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1659</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>ざきさん</td>\n",
       "      <td>みなさんファイルをアップしましたか？</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1683</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>あ</td>\n",
       "      <td>今アップしました！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id reply  gid   cname                body         Argumentation(H)  \\\n",
       "0  1593    \\N    1  世界のわたべ         よろしくお願いします。  non-argumentative moves   \n",
       "1  1598    \\N    1    ざきさん              よろしくです  non-argumentative moves   \n",
       "2  1606    \\N    1       あ              よろしくです  non-argumentative moves   \n",
       "3  1659    \\N    1    ざきさん  みなさんファイルをアップしましたか？  non-argumentative moves   \n",
       "4  1683    \\N    1       あ           今アップしました！  non-argumentative moves   \n",
       "\n",
       "          Argumentation(S)  \n",
       "0  non-argumentative moves  \n",
       "1  non-argumentative moves  \n",
       "2  non-argumentative moves  \n",
       "3  non-argumentative moves  \n",
       "4  non-argumentative moves  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_H_match_df = S_H_171116_df[S_H_171116_df['Argumentation(H)'] == S_H_171116_df['Argumentation(S)']].reset_index(drop=True)\n",
    "S_H_match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.158599Z",
     "start_time": "2017-12-07T08:46:26.153434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No.                 0\n",
       "返信元                 0\n",
       "gid                 0\n",
       "ニックネーム              0\n",
       "発言内容                0\n",
       "Argumentation(A)    0\n",
       "Watanabe.2          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_W_match_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.165251Z",
     "start_time": "2017-12-07T08:46:26.159779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "reply               0\n",
       "gid                 0\n",
       "cname               0\n",
       "body                0\n",
       "Argumentation(H)    0\n",
       "Argumentation(S)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_H_match_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A_WとS_Hのheaderの統一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.168652Z",
     "start_time": "2017-12-07T08:46:26.166412Z"
    }
   },
   "outputs": [],
   "source": [
    "header = ['id', 'reply', 'group_id', 'cname', 'body', 'Argumentation_A', 'Argumentation_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.173721Z",
     "start_time": "2017-12-07T08:46:26.170021Z"
    }
   },
   "outputs": [],
   "source": [
    "A_W_df.columns = header\n",
    "S_H_171116_df.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.180091Z",
     "start_time": "2017-12-07T08:46:26.174888Z"
    }
   },
   "outputs": [],
   "source": [
    "A_W_match_df.columns = header\n",
    "S_H_match_df.columns = header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A_WとS_Hの結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.187208Z",
     "start_time": "2017-12-07T08:46:26.181244Z"
    }
   },
   "outputs": [],
   "source": [
    "All_df = pd.concat([A_W_df, S_H_171116_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.191795Z",
     "start_time": "2017-12-07T08:46:26.188480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9083, 7)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相談なしで一致したA_W_match_dfとS_H_match_dfの結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.198236Z",
     "start_time": "2017-12-07T08:46:26.193124Z"
    }
   },
   "outputs": [],
   "source": [
    "match_df = pd.concat([A_W_match_df, S_H_match_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.202746Z",
     "start_time": "2017-12-07T08:46:26.199467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7765, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T10:01:52.762651Z",
     "start_time": "2017-12-08T10:01:52.757606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.48937575690852"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_df.shape[0]/All_df.shape[0] *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一応データの整理はここまで\n",
    "- 必要な前処理などは気づき次第、適時修正する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 現状の整理\n",
    "- 人間A, Bそれぞれのタグ取り出しはできそう\n",
    "- 人間ABの相談なし一致のタグはA,Bのタグを比較すればできそう    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここからは分類器に入力するための整形処理\n",
    "- Epistemicの分類\n",
    "    - 人間Aのタグ\n",
    "    - 人間Bのタグ\n",
    "    - 人間ABの相談なし一致のタグ\n",
    "- Argumentationの分類\n",
    "    - 人間Aのタグ\n",
    "    - 人間Bのタグ\n",
    "    - 人間ABの相談なし一致のタグ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## どのように処理していくか\n",
    "- これまでは、扱うラベルなどが変わるたびにnumpy配列の列番号を変えなくてはならなかった\n",
    "- これからは、扱うデータの形式を統一したい\n",
    "- そのためにどうするか\n",
    "    - 必要なデータの構成を決める\n",
    "    - data frameから必要のない列を削ったnumpy配列を作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類器に入力するために必要なデータ\n",
    "- id\n",
    "- reply\n",
    "- group_id\n",
    "- cname\n",
    "- body\n",
    "- label(Epistemic or Argumentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.209826Z",
     "start_time": "2017-12-07T08:46:26.203985Z"
    }
   },
   "outputs": [],
   "source": [
    "# データの形式の定義\n",
    "data_format = ['id', 'reply', 'group_id', 'cname', 'body', 'label']\n",
    "# 名前からデータのindexに変換する辞書\n",
    "data_index = {column : i for i, column in enumerate(data_format)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.215977Z",
     "start_time": "2017-12-07T08:46:26.210935Z"
    }
   },
   "outputs": [],
   "source": [
    "id = 0\n",
    "reply = 1\n",
    "group_id = 2\n",
    "cname = 3\n",
    "body = 4\n",
    "label = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.221609Z",
     "start_time": "2017-12-07T08:46:26.217211Z"
    }
   },
   "outputs": [],
   "source": [
    "df_index = {column: i for i, column in enumerate(All_df)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-25T09:34:12.495749Z",
     "start_time": "2017-11-25T09:34:12.492466Z"
    }
   },
   "source": [
    "### All_dfから共通して取り出す列名\n",
    "- ['id', 'reply', 'group_id', 'cname', 'body']\n",
    "\n",
    "### 変動する列名\n",
    "- label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.228963Z",
     "start_time": "2017-12-07T08:46:26.222822Z"
    }
   },
   "outputs": [],
   "source": [
    "df_use = [0, 1, 2, 3, 4]\n",
    "# All_df_index['ラベル名']を変更して取り出すラベルを分ける\n",
    "# label_position = df_index['Argumentation_A']\n",
    "# label_position = df_index['Argumentation_B']\n",
    "label_position = df_index['Argumentation_B']\n",
    "df_use.append(label_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.234603Z",
     "start_time": "2017-12-07T08:46:26.230153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 6]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要のない列を取り除いて、入力用のdfを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.241353Z",
     "start_time": "2017-12-07T08:46:26.235708Z"
    }
   },
   "outputs": [],
   "source": [
    "delete_columns_list = []\n",
    "#for i, column in enumerate(All_df):\n",
    "for i, column in enumerate(match_df):\n",
    "    if not i in df_use:\n",
    "        delete_columns_list.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.248989Z",
     "start_time": "2017-12-07T08:46:26.242523Z"
    }
   },
   "outputs": [],
   "source": [
    "#input_df = All_df.drop(delete_columns_list, axis=1)\n",
    "input_df = match_df.drop(delete_columns_list, axis=1)\n",
    "# input_df = A_W_consulted_df.drop(delete_columns_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.253033Z",
     "start_time": "2017-12-07T08:46:26.250158Z"
    }
   },
   "outputs": [],
   "source": [
    "input_df.columns = data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.278562Z",
     "start_time": "2017-12-07T08:46:26.254280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reply</th>\n",
       "      <th>group_id</th>\n",
       "      <th>cname</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>よろしくお願いします！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>哲</td>\n",
       "      <td>よろしくお願いします</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>名前なのが恥ずかしいです…\\n\\nよろしくお願いします！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>早速課題やっちゃいましょう！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>163.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>やっちゃいましょう\\n\\nmoodleはゴミです！</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>194.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>使いにくいです(笑)</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>302.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>哲</td>\n",
       "      <td>同意です</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>309.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>以前インタラクティブアート受講していたのですが、その時に課題が不具合で出せなくなっていた時期...</td>\n",
       "      <td>grounded claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>385.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>学習環境として必要最低限の機能は備えていると思うが、操作性の面ではPCの最低限の知識があるこ...</td>\n",
       "      <td>grounded and qualified claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>ほぼほぼ同意です</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>528.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>他に何か考えてることなどありますか</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>693.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>他に意見ありますかー？</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>746.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>哲さんどうですか？</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>813.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>１度共有テキスト全部消して現在の回答案書きます！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>830.0</td>\n",
       "      <td>746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>哲</td>\n",
       "      <td>&gt; 哲さんどうですか？\\n\\n自分もみなさんの意見に同意です</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>899.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>こちらの回答案でよければ課題回答しちゃいますけど大丈夫ですか？</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>916.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>自分は平気です</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>934.0</td>\n",
       "      <td>899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>哲</td>\n",
       "      <td>よろしくお願いします！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>964.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>完了です！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>990.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>お疲れ様です！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1017.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>１番乗りおめでとう！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1031.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>ありがとうございます(笑)</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1048.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>でた！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1066.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>哲</td>\n",
       "      <td>お役に立てず申し訳ございません\\n\\nありがとうごいました！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1101.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>仙波</td>\n",
       "      <td>お疲れ様でした！\\n\\nまた何かあればその時はよろしくです</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1107.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>まこぴす</td>\n",
       "      <td>いえいえ！お疲れさまでした！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>マニン</td>\n",
       "      <td>よろしくー</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>90.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Houdini</td>\n",
       "      <td>よろしゅー</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>91.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>あひるぅ</td>\n",
       "      <td>おはようございました</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>158.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>あひるぅ</td>\n",
       "      <td>どう思いますか？？</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7735</th>\n",
       "      <td>6189.0</td>\n",
       "      <td>6183</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>みずき</td>\n",
       "      <td>&gt; 共有テキストに書いてある感じで提出しちゃいますか？\\nいや、変更があればどんどん訂正して...</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7736</th>\n",
       "      <td>6204.0</td>\n",
       "      <td>6189</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>まささ</td>\n",
       "      <td>&gt; &amp;gt; 共有テキストに書いてある感じで提出しちゃいますか？\\n\\n&gt; いや、変更があれ...</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7737</th>\n",
       "      <td>6224.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>共有テキストの下半分のやつで出しちゃおうと思ってる</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7738</th>\n",
       "      <td>6237.0</td>\n",
       "      <td>6224</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>みずき</td>\n",
       "      <td>&gt; 共有テキストの下半分のやつで出しちゃおうと思ってる\\n了解です！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7739</th>\n",
       "      <td>6241.0</td>\n",
       "      <td>6224</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>まささ</td>\n",
       "      <td>&gt; 共有テキストの下半分のやつで出しちゃおうと思ってる\\nわかりました！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7740</th>\n",
       "      <td>6243.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>じゃあ提出しておきますね</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7741</th>\n",
       "      <td>6254.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>提出しました</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742</th>\n",
       "      <td>6257.0</td>\n",
       "      <td>6254</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>まささ</td>\n",
       "      <td>&gt; 提出しました\\nありがとうございます！！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7743</th>\n",
       "      <td>6264.0</td>\n",
       "      <td>6254</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>みずき</td>\n",
       "      <td>&gt; 提出しました\\nありがとうございます！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7744</th>\n",
       "      <td>6266.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>共有テキスト一回消しちゃいます？</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>6278.0</td>\n",
       "      <td>6266</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>まささ</td>\n",
       "      <td>&gt; 共有テキスト一回消しちゃいます？\\nそうしましょう</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7746</th>\n",
       "      <td>6280.0</td>\n",
       "      <td>6266</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>みずき</td>\n",
       "      <td>&gt; 共有テキスト一回消しちゃいます？\\nそうしましょう！で、課題2やりましょう！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7747</th>\n",
       "      <td>6288.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>TinCanとは多種多様な学習活動の履歴を記録・検索・抽出するためのしすてむ</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748</th>\n",
       "      <td>6326.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>SCORMの次世代版でビッグデータにも対応してるらしい</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7749</th>\n",
       "      <td>6363.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>まささ</td>\n",
       "      <td>スマホアプリやタブレットでの利用もできる</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7750</th>\n",
       "      <td>6388.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>今出てきた意見全部繋げちゃう？</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>6404.0</td>\n",
       "      <td>6388</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>みずき</td>\n",
       "      <td>&gt; 今出てきた意見全部繋げちゃう？\\n今つなげようとしてます！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7752</th>\n",
       "      <td>6410.0</td>\n",
       "      <td>6404</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>&gt; &amp;gt; 今出てきた意見全部繋げちゃう？\\n\\n&gt; 今つなげようとしてます！\\nお願いします</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7753</th>\n",
       "      <td>6415.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>まささ</td>\n",
       "      <td>次世代SCORMとして発表された規格で、正式名称はExperience API（略称：xAP...</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7754</th>\n",
       "      <td>6419.0</td>\n",
       "      <td>6404</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>まささ</td>\n",
       "      <td>&gt; &amp;gt; 今出てきた意見全部繋げちゃう？\\n\\n&gt; 今つなげようとしてます！\\n\\nあり...</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>6435.0</td>\n",
       "      <td>6415</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>みずき</td>\n",
       "      <td>&gt; 次世代SCORMとして発表された規格で、正式名称はExperience API（略称：x...</td>\n",
       "      <td>simple claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7756</th>\n",
       "      <td>6441.0</td>\n",
       "      <td>6436</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>みずき</td>\n",
       "      <td>&gt; 共有テキストので良いと思います\\n大丈夫ですか？</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>6449.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>提出お願いします</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>6451.0</td>\n",
       "      <td>6443</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>みずき</td>\n",
       "      <td>&gt; &amp;gt; 共有テキストので良いと思います\\n\\n&gt; 私もそう思います、分かりやすくていい...</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>6459.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>みずき</td>\n",
       "      <td>課題2提出完了です！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760</th>\n",
       "      <td>6463.0</td>\n",
       "      <td>6459</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>まささ</td>\n",
       "      <td>&gt; 課題2提出完了です！\\nありがとうございます！</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>6467.0</td>\n",
       "      <td>6459</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>&gt; 課題2提出完了です！\\nありがとうございます</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>6477.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>課題3やりますか</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7763</th>\n",
       "      <td>6491.0</td>\n",
       "      <td>6477</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>まささ</td>\n",
       "      <td>&gt; 課題3やりますか\\nやりましょう、共有テキストいったん消しちゃいますね</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7764</th>\n",
       "      <td>6521.0</td>\n",
       "      <td>\\N</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>オノヅカ</td>\n",
       "      <td>「何を」の部分の選択肢が後1つくらい欲しいかな</td>\n",
       "      <td>non-argumentative moves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7765 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id reply  group_id    cname  \\\n",
       "0        1.0    \\N       1.0     まこぴす   \n",
       "1       31.0    \\N       1.0        哲   \n",
       "2       70.0    \\N       1.0       仙波   \n",
       "3      119.0    \\N       1.0     まこぴす   \n",
       "4      163.0    \\N       1.0       仙波   \n",
       "5      194.0    \\N       1.0     まこぴす   \n",
       "6      302.0    \\N       1.0        哲   \n",
       "7      309.0    \\N       1.0       仙波   \n",
       "8      385.0    \\N       1.0     まこぴす   \n",
       "9      500.0    \\N       1.0       仙波   \n",
       "10     528.0    \\N       1.0       仙波   \n",
       "11     693.0    \\N       1.0     まこぴす   \n",
       "12     746.0    \\N       1.0     まこぴす   \n",
       "13     813.0    \\N       1.0     まこぴす   \n",
       "14     830.0   746       1.0        哲   \n",
       "15     899.0    \\N       1.0     まこぴす   \n",
       "16     916.0    \\N       1.0       仙波   \n",
       "17     934.0   899       1.0        哲   \n",
       "18     964.0    \\N       1.0     まこぴす   \n",
       "19     990.0    \\N       1.0       仙波   \n",
       "20    1017.0    \\N       1.0       \\N   \n",
       "21    1031.0    \\N       1.0     まこぴす   \n",
       "22    1048.0    \\N       1.0       仙波   \n",
       "23    1066.0    \\N       1.0        哲   \n",
       "24    1101.0    \\N       1.0       仙波   \n",
       "25    1107.0    \\N       1.0     まこぴす   \n",
       "26      27.0    \\N       2.0      マニン   \n",
       "27      90.0    \\N       2.0  Houdini   \n",
       "28      91.0    \\N       2.0     あひるぅ   \n",
       "29     158.0    \\N       2.0     あひるぅ   \n",
       "...      ...   ...       ...      ...   \n",
       "7735  6189.0  6183   10001.0      みずき   \n",
       "7736  6204.0  6189   10001.0      まささ   \n",
       "7737  6224.0    \\N   10001.0     オノヅカ   \n",
       "7738  6237.0  6224   10001.0      みずき   \n",
       "7739  6241.0  6224   10001.0      まささ   \n",
       "7740  6243.0    \\N   10001.0     オノヅカ   \n",
       "7741  6254.0    \\N   10001.0     オノヅカ   \n",
       "7742  6257.0  6254   10001.0      まささ   \n",
       "7743  6264.0  6254   10001.0      みずき   \n",
       "7744  6266.0    \\N   10001.0     オノヅカ   \n",
       "7745  6278.0  6266   10001.0      まささ   \n",
       "7746  6280.0  6266   10001.0      みずき   \n",
       "7747  6288.0    \\N   10001.0     オノヅカ   \n",
       "7748  6326.0    \\N   10001.0     オノヅカ   \n",
       "7749  6363.0    \\N   10001.0      まささ   \n",
       "7750  6388.0    \\N   10001.0     オノヅカ   \n",
       "7751  6404.0  6388   10001.0      みずき   \n",
       "7752  6410.0  6404   10001.0     オノヅカ   \n",
       "7753  6415.0    \\N   10001.0      まささ   \n",
       "7754  6419.0  6404   10001.0      まささ   \n",
       "7755  6435.0  6415   10001.0      みずき   \n",
       "7756  6441.0  6436   10001.0      みずき   \n",
       "7757  6449.0    \\N   10001.0     オノヅカ   \n",
       "7758  6451.0  6443   10001.0      みずき   \n",
       "7759  6459.0    \\N   10001.0      みずき   \n",
       "7760  6463.0  6459   10001.0      まささ   \n",
       "7761  6467.0  6459   10001.0     オノヅカ   \n",
       "7762  6477.0    \\N   10001.0     オノヅカ   \n",
       "7763  6491.0  6477   10001.0      まささ   \n",
       "7764  6521.0    \\N   10001.0     オノヅカ   \n",
       "\n",
       "                                                   body  \\\n",
       "0                                           よろしくお願いします！   \n",
       "1                                            よろしくお願いします   \n",
       "2                          名前なのが恥ずかしいです…\\n\\nよろしくお願いします！   \n",
       "3                                        早速課題やっちゃいましょう！   \n",
       "4                             やっちゃいましょう\\n\\nmoodleはゴミです！   \n",
       "5                                            使いにくいです(笑)   \n",
       "6                                                  同意です   \n",
       "7     以前インタラクティブアート受講していたのですが、その時に課題が不具合で出せなくなっていた時期...   \n",
       "8     学習環境として必要最低限の機能は備えていると思うが、操作性の面ではPCの最低限の知識があるこ...   \n",
       "9                                              ほぼほぼ同意です   \n",
       "10                                    他に何か考えてることなどありますか   \n",
       "11                                          他に意見ありますかー？   \n",
       "12                                            哲さんどうですか？   \n",
       "13                             １度共有テキスト全部消して現在の回答案書きます！   \n",
       "14                       > 哲さんどうですか？\\n\\n自分もみなさんの意見に同意です   \n",
       "15                      こちらの回答案でよければ課題回答しちゃいますけど大丈夫ですか？   \n",
       "16                                              自分は平気です   \n",
       "17                                          よろしくお願いします！   \n",
       "18                                                完了です！   \n",
       "19                                              お疲れ様です！   \n",
       "20                                           １番乗りおめでとう！   \n",
       "21                                        ありがとうございます(笑)   \n",
       "22                                                  でた！   \n",
       "23                       お役に立てず申し訳ございません\\n\\nありがとうごいました！   \n",
       "24                        お疲れ様でした！\\n\\nまた何かあればその時はよろしくです   \n",
       "25                                       いえいえ！お疲れさまでした！   \n",
       "26                                                よろしくー   \n",
       "27                                                よろしゅー   \n",
       "28                                           おはようございました   \n",
       "29                                            どう思いますか？？   \n",
       "...                                                 ...   \n",
       "7735  > 共有テキストに書いてある感じで提出しちゃいますか？\\nいや、変更があればどんどん訂正して...   \n",
       "7736  > &gt; 共有テキストに書いてある感じで提出しちゃいますか？\\n\\n> いや、変更があれ...   \n",
       "7737                          共有テキストの下半分のやつで出しちゃおうと思ってる   \n",
       "7738                 > 共有テキストの下半分のやつで出しちゃおうと思ってる\\n了解です！   \n",
       "7739               > 共有テキストの下半分のやつで出しちゃおうと思ってる\\nわかりました！   \n",
       "7740                                       じゃあ提出しておきますね   \n",
       "7741                                             提出しました   \n",
       "7742                             > 提出しました\\nありがとうございます！！   \n",
       "7743                              > 提出しました\\nありがとうございます！   \n",
       "7744                                   共有テキスト一回消しちゃいます？   \n",
       "7745                        > 共有テキスト一回消しちゃいます？\\nそうしましょう   \n",
       "7746           > 共有テキスト一回消しちゃいます？\\nそうしましょう！で、課題2やりましょう！   \n",
       "7747             TinCanとは多種多様な学習活動の履歴を記録・検索・抽出するためのしすてむ   \n",
       "7748                        SCORMの次世代版でビッグデータにも対応してるらしい   \n",
       "7749                               スマホアプリやタブレットでの利用もできる   \n",
       "7750                                    今出てきた意見全部繋げちゃう？   \n",
       "7751                    > 今出てきた意見全部繋げちゃう？\\n今つなげようとしてます！   \n",
       "7752   > &gt; 今出てきた意見全部繋げちゃう？\\n\\n> 今つなげようとしてます！\\nお願いします   \n",
       "7753  次世代SCORMとして発表された規格で、正式名称はExperience API（略称：xAP...   \n",
       "7754  > &gt; 今出てきた意見全部繋げちゃう？\\n\\n> 今つなげようとしてます！\\n\\nあり...   \n",
       "7755  > 次世代SCORMとして発表された規格で、正式名称はExperience API（略称：x...   \n",
       "7756                         > 共有テキストので良いと思います\\n大丈夫ですか？   \n",
       "7757                                           提出お願いします   \n",
       "7758  > &gt; 共有テキストので良いと思います\\n\\n> 私もそう思います、分かりやすくていい...   \n",
       "7759                                         課題2提出完了です！   \n",
       "7760                          > 課題2提出完了です！\\nありがとうございます！   \n",
       "7761                           > 課題2提出完了です！\\nありがとうございます   \n",
       "7762                                           課題3やりますか   \n",
       "7763              > 課題3やりますか\\nやりましょう、共有テキストいったん消しちゃいますね   \n",
       "7764                            「何を」の部分の選択肢が後1つくらい欲しいかな   \n",
       "\n",
       "                             label  \n",
       "0          non-argumentative moves  \n",
       "1          non-argumentative moves  \n",
       "2          non-argumentative moves  \n",
       "3          non-argumentative moves  \n",
       "4                     simple claim  \n",
       "5                     simple claim  \n",
       "6                     simple claim  \n",
       "7                   grounded claim  \n",
       "8     grounded and qualified claim  \n",
       "9                     simple claim  \n",
       "10         non-argumentative moves  \n",
       "11         non-argumentative moves  \n",
       "12         non-argumentative moves  \n",
       "13         non-argumentative moves  \n",
       "14                    simple claim  \n",
       "15         non-argumentative moves  \n",
       "16         non-argumentative moves  \n",
       "17         non-argumentative moves  \n",
       "18         non-argumentative moves  \n",
       "19         non-argumentative moves  \n",
       "20         non-argumentative moves  \n",
       "21         non-argumentative moves  \n",
       "22         non-argumentative moves  \n",
       "23         non-argumentative moves  \n",
       "24         non-argumentative moves  \n",
       "25         non-argumentative moves  \n",
       "26         non-argumentative moves  \n",
       "27         non-argumentative moves  \n",
       "28         non-argumentative moves  \n",
       "29         non-argumentative moves  \n",
       "...                            ...  \n",
       "7735       non-argumentative moves  \n",
       "7736       non-argumentative moves  \n",
       "7737       non-argumentative moves  \n",
       "7738       non-argumentative moves  \n",
       "7739       non-argumentative moves  \n",
       "7740       non-argumentative moves  \n",
       "7741       non-argumentative moves  \n",
       "7742       non-argumentative moves  \n",
       "7743       non-argumentative moves  \n",
       "7744       non-argumentative moves  \n",
       "7745       non-argumentative moves  \n",
       "7746       non-argumentative moves  \n",
       "7747                  simple claim  \n",
       "7748                  simple claim  \n",
       "7749                  simple claim  \n",
       "7750       non-argumentative moves  \n",
       "7751       non-argumentative moves  \n",
       "7752       non-argumentative moves  \n",
       "7753                  simple claim  \n",
       "7754       non-argumentative moves  \n",
       "7755                  simple claim  \n",
       "7756       non-argumentative moves  \n",
       "7757       non-argumentative moves  \n",
       "7758       non-argumentative moves  \n",
       "7759       non-argumentative moves  \n",
       "7760       non-argumentative moves  \n",
       "7761       non-argumentative moves  \n",
       "7762       non-argumentative moves  \n",
       "7763       non-argumentative moves  \n",
       "7764       non-argumentative moves  \n",
       "\n",
       "[7765 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出現頻度が少ないラベルを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:26.284000Z",
     "start_time": "2017-12-07T08:46:26.280004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'non-argumentative moves': 4899, 'simple claim': 2622, 'grounded claim': 228, 'qualified claim': 13, 'grounded and qualified claim': 3})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(input_df['label'])\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T10:16:01.763165Z",
     "start_time": "2017-12-08T10:16:01.757978Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = input_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T10:16:24.886639Z",
     "start_time": "2017-12-08T10:16:24.881672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7765, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:33:03.401588Z",
     "start_time": "2017-12-06T01:33:03.303337Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(xs, trim_citation=False):\n",
    "    zs = [\"\"] * len(xs)\n",
    "    '''全角空白'''\n",
    "    for i, l in enumerate(xs):\n",
    "        xs[i] = re.sub('　', ' ', str(l))\n",
    "    '''多重引用'''\n",
    "    for i, l in enumerate(xs):\n",
    "        xs[i] = re.sub('＆ｇｔ；', '＞', l)\n",
    "    '''引用部分は除外'''\n",
    "    count_refer = 0\n",
    "    for i, l in enumerate(xs):\n",
    "        sen = \"\"\n",
    "        have_refer = 1\n",
    "        for x in l.split('\\n'):\n",
    "            if len(x) == 0:\n",
    "                continue\n",
    "            elif x[0].encode('utf-8') == '＞'.encode('utf-8'):\n",
    "                have_refer = 1\n",
    "                x = x[1:]\n",
    "                if len(x) > 0 and x[0].encode('utf-8') != '＞'.encode('utf-8') and \\\n",
    "                        x[0:2].encode('utf-8') != ' ＞'.encode('utf-8') and x != ' ':\n",
    "                    if trim_citation:\n",
    "                        zs[i] += x + '\\n'\n",
    "                    else:\n",
    "                        sen = sen + \"＞ \" + x + '\\n'\n",
    "                continue\n",
    "            else:\n",
    "                sen = sen + x + '\\n'\n",
    "        xs[i] = sen.strip()\n",
    "        count_refer += have_refer\n",
    "    '''顔文字'''\n",
    "    pat = re.compile('（[^ぁ-んァ-ン一-龠]+?）', re.U)\n",
    "    for i, l in enumerate(xs):\n",
    "        xs[i] = re.sub(pat, ' KAOMOJI ', l)\n",
    "    '''日本語及び記号{？！ー〜。、} のみ有効'''\n",
    "    pat = re.compile('[^＞ Ａ-Ｚａ-ｚ０-９ぁ-んァ-ン一-龠？！ー〜。、\\n]+?', re.U)\n",
    "    for i, l in enumerate(xs):\n",
    "        xs[i] = re.sub(pat, '', l)\n",
    "    '''記号繰り返し'''\n",
    "    pat_1 = re.compile('[ｗ]{1,}', re.U)\n",
    "    pat_2 = re.compile('[？]{1,}', re.U)\n",
    "    pat_3 = re.compile('[！]{1,}', re.U)\n",
    "    pat_4 = re.compile('[～]{1,}', re.U)\n",
    "    pat_5 = re.compile('[ー]{1,}', re.U)\n",
    "    pat_6 = re.compile('[。]{1,}', re.U)\n",
    "\n",
    "    for i, l in enumerate(xs):\n",
    "        l = re.sub(pat_1, 'ｗ', l)\n",
    "        l = re.sub(pat_2, '？', l)\n",
    "        l = re.sub(pat_3, '！', l)\n",
    "        l = re.sub(pat_4, '～', l)\n",
    "        l = re.sub(pat_5, 'ー', l)\n",
    "        l = re.sub(pat_6, '。', l)\n",
    "        xs[i] = l\n",
    "\n",
    "    if trim_citation:\n",
    "        return zs\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:33:03.431872Z",
     "start_time": "2017-12-06T01:33:03.402528Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_xs(orig, trim_citation=False, use_seq2seq=False):\n",
    "\n",
    "    tmp = np.copy(orig)\n",
    "    xs = tmp[:, body]\n",
    "    zs = preprocess(xs, trim_citation=(trim_citation or use_seq2seq))\n",
    "\n",
    "    if use_seq2seq:\n",
    "        tmp_prev = np.roll(tmp, 1, axis=0)\n",
    "        tmp_prev[0, 0] = \"\"\n",
    "        ts = tmp[:, [1, 2]]\n",
    "        xs_prev = tmp_prev[:, body]\n",
    "\n",
    "        for i in range(len(tmp)):\n",
    "            if tmp[i, group_id] != tmp_prev[i, group_id]:  # group が異なる\n",
    "                xs_prev[i] = \"\"\n",
    "        preprocess(xs_prev, trim_citation=True)\n",
    "\n",
    "        for i in range(len(xs)):\n",
    "            replay_to = tmp[i, 2]\n",
    "            if zs[i] != \"\":\n",
    "                xs_prev[i] = zs[i]\n",
    "            elif replay_to != -1:\n",
    "                a = xs[:i][tmp[:i, 1] == replay_to]\n",
    "                if len(a) != 0:\n",
    "                    xs_prev[i] = a[-1]\n",
    "\n",
    "        return xs, xs_prev\n",
    "    else:\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:33:03.441126Z",
     "start_time": "2017-12-06T01:33:03.432792Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_doc(xs):\n",
    "    doc = []\n",
    "    for ll in xs:\n",
    "        sen = []\n",
    "        for l in ll.split('\\n'):\n",
    "            for w in mc.parse(l).split('\\n'):\n",
    "                mx = w.split('\\t')\n",
    "                if len(mx[0]) > 0:\n",
    "                    sen.append(mx[0])\n",
    "        doc.append(sen)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:33:04.917685Z",
     "start_time": "2017-12-06T01:33:03.442024Z"
    }
   },
   "outputs": [],
   "source": [
    "xs, xs_pre = make_xs(input_data, trim_citation=True, use_seq2seq=True)\n",
    "doc = get_doc(xs)\n",
    "doc_pre = get_doc(xs_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:33:04.921471Z",
     "start_time": "2017-12-06T01:33:04.918689Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in doc[:10]:\n",
    "    print(\" \".join(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 単語の数値変換\n",
    "wd_setにdocとdoc_preに格納されている単語(listの要素単位)をカウンターで数え上げる  \n",
    "wd_aryはカウントされた単語のリスト(Counter==dictのkey)  \n",
    "wd_cntは各単語の出現数(dictのvalue)  \n",
    "wd_aryを単語の出現数(昇順)に操作  \n",
    "wd_cntを昇順に直す出現数で昇順に並べ替え済みのwd_aryをもとにenumrateで単語:単語idのdictを作成\n",
    "\n",
    "python2→3の変更点で、dict.keys()がiter的なので返ってきてしまうからlist()でキャストする必要あった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:33:04.973262Z",
     "start_time": "2017-12-06T01:33:04.922391Z"
    }
   },
   "outputs": [],
   "source": [
    "wd_set = Counter([x for sen in doc + doc_pre for x in sen])\n",
    "wd_ary = np.array(list(wd_set.keys()))\n",
    "wd_cnt = np.array(list(wd_set.values()))\n",
    "wd_ary = wd_ary[np.argsort(wd_cnt)[::-1]]\n",
    "wd_cnt.sort()\n",
    "wd_cnt = wd_cnt[::-1]\n",
    "wd_to_id = {wd: i for i, wd in enumerate(wd_ary)}\n",
    "lb_to_id = {lb: i for i, lb in enumerate({x for x in input_data[:, label]})}\n",
    "id_to_wd = {wd_to_id[wd]: wd for wd in wd_to_id.keys()}\n",
    "id_to_lb = {lb_to_id[lb]: lb for lb in lb_to_id.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:33:05.215007Z",
     "start_time": "2017-12-06T01:33:05.158967Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(list(wd_ary)[i], list(wd_cnt)[i])\n",
    "    #print(list(wd_set.keys())[i], list(wd_set.values())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:33:06.176772Z",
     "start_time": "2017-12-06T01:33:05.893599Z"
    }
   },
   "outputs": [],
   "source": [
    "KIND = len(list(lb_to_id.keys()))\n",
    "CUT_OFF = 2\n",
    "\n",
    "print(\"words kinds:\",\n",
    "      len(wd_cnt), \"words>=\" + str(CUT_OFF) + \":\", np.sum(wd_cnt >= CUT_OFF))\n",
    "print(\"all words num:\", np.sum(wd_cnt))\n",
    "print(\"all words num:\", np.sum(wd_cnt[wd_cnt >= CUT_OFF]))\n",
    "\n",
    "other_id = np.sum(wd_cnt >= CUT_OFF)\n",
    "wd_to_id.update({wd: other_id for wd in wd_ary[wd_cnt < CUT_OFF]})\n",
    "print(other_id)\n",
    "id_to_wd[other_id] = '[X]'\n",
    "\n",
    "print(max(wd_to_id.values()))\n",
    "\n",
    "with open('data/Argumentation_FA_id_to_wd.pickle', mode='wb') as f:\n",
    "    pickle.dump(id_to_wd, f)\n",
    "with open('data/Argumentation_FA_wd_to_id.pickle', mode='wb') as f:\n",
    "    pickle.dump(wd_to_id, f)\n",
    "with open('data/Argumentation_FA_wd_set.pickle', mode='wb') as f:\n",
    "    pickle.dump(wd_set, f)\n",
    "with open('data/Argumentation_FA_id_to_lb.pickle', mode='wb') as f:\n",
    "    pickle.dump(id_to_lb, f)\n",
    "pd.DataFrame(\n",
    "    np.array(list(id_to_lb.items())).T, index=[\"ラベルid\", \"ラベルname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:33:06.525363Z",
     "start_time": "2017-12-06T01:33:06.345758Z"
    }
   },
   "outputs": [],
   "source": [
    "of = open(\"data/Argumentation_FA_edu_data.txt\", \"w\")\n",
    "for i, (sen, lb) in enumerate(zip(np.array(doc), input_data[:, label])):\n",
    "    sen_str = \"\".join([str(wd_to_id[wd]) + \" \" for wd in sen])\n",
    "    print_str = str(lb_to_id[lb]) + \" \" + str(lb_to_id[lb]) + \" \" + sen_str\n",
    "    print(print_str, file=of)\n",
    "of.close()\n",
    "\n",
    "of = open(\"data/Argumentation_FA_edu_data_pre.txt\", \"w\")\n",
    "for i, sen in enumerate(np.array(doc_pre)):\n",
    "    sen_str = \"\".join([str(wd_to_id[wd]) + \" \" for wd in sen])\n",
    "    print(sen_str, file=of)\n",
    "of.close()\n",
    "\n",
    "print(max([len(sen) for sen in doc]))\n",
    "\n",
    "print(KIND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:45.679200Z",
     "start_time": "2017-12-07T08:46:45.659246Z"
    }
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import imp\n",
    "# imp.reload(datagen)\n",
    "#import datagen\n",
    "import datetime\n",
    "import time\n",
    "from chainer import serializers\n",
    "from chainer import optimizers\n",
    "from chainer import cuda\n",
    "from src import models\n",
    "import imp\n",
    "try:\n",
    "    cuda.check_cuda_available()\n",
    "    import cupy\n",
    "    xp = cupy\n",
    "except:\n",
    "    xp = np\n",
    "cuda.get_device(1).use()\n",
    "\n",
    "with open('data/Argumentation_FA_id_to_lb.pickle', mode='rb') as f:\n",
    "    id_to_code = pickle.load(f)\n",
    "KIND = len(id_to_code)\n",
    "\n",
    "print((\"KIND\", KIND))\n",
    "#print((\"data.kind\", data.kind))\n",
    "\n",
    "pd.DataFrame(np.array(list(id_to_code.items())).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:48.013496Z",
     "start_time": "2017-12-07T08:46:46.343858Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "\n",
    "#import models\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    '''\n",
    "    Read the data from a file.\n",
    "    start_symbol   : -2 mod |Sigma|\n",
    "    end_symbol     : -1 mod |Sigma|\n",
    "    padding_symbol : -1 mod |Sigma|\n",
    "    '''\n",
    "\n",
    "    def make_pos_data(self, tmp, start_symbol, end_symbol, padding_symbol):\n",
    "        if end_symbol is not None:\n",
    "            tmp = [[start_symbol] + s + [end_symbol] for s in tmp]\n",
    "        pos = np.cumsum([0] + [len(lst) for lst in tmp])\n",
    "        pos = np.c_[pos, np.roll(pos, -1)][:-1]\n",
    "        data = np.asarray([a for lst in tmp for a in lst], dtype=np.int32)\n",
    "        return pos, data\n",
    "\n",
    "    def __init__(self,\n",
    "                 filename,\n",
    "                 filename2=None,\n",
    "                 fmt=\"pautomac\",\n",
    "                 start_symbol=-2,\n",
    "                 end_symbol=-1,\n",
    "                 padding_symbol=-1,\n",
    "                 all_train=False,\n",
    "                 all_test=False):\n",
    "        self.all_train = all_train\n",
    "        self.all_test = all_test\n",
    "        self.has_pre = (filename2 != None)\n",
    "        if fmt == \"pautomac\":\n",
    "            tmp = [l.strip().split()[1:]\n",
    "                   for l in open(filename).readlines()][1:]\n",
    "            self.label = None\n",
    "        elif fmt == \"labeled\":\n",
    "            tmp = [l.strip().split()[1:] for l in open(filename).readlines()]\n",
    "            self.label = np.asarray(\n",
    "                [l.strip().split()[0] for l in open(filename).readlines()],\n",
    "                dtype=np.int32)\n",
    "        elif fmt == \"2-labeled\":\n",
    "            tmp = [l.strip().split()[2:] for l in open(filename).readlines()]\n",
    "            if self.has_pre:\n",
    "                tmp_pre = [\n",
    "                    l.strip().split() for l in open(filename2).readlines()\n",
    "                ]\n",
    "            self.label = np.asarray(\n",
    "                [l.strip().split()[0:2] for l in open(filename).readlines()],\n",
    "                dtype=np.int32)\n",
    "\n",
    "        self.pos, self.data = self.make_pos_data(tmp, start_symbol, end_symbol,\n",
    "                                                 padding_symbol)\n",
    "        if self.has_pre:\n",
    "            self.pos_pre, self.data_pre = self.make_pos_data(\n",
    "                tmp_pre, start_symbol, end_symbol, padding_symbol)\n",
    "        self.kind = np.max(self.data) + 3\n",
    "        self.data = self.data % self.kind\n",
    "        self.start_symbol = start_symbol % self.kind\n",
    "        self.end_symbol = end_symbol % self.kind\n",
    "        self.padding_symbol = padding_symbol % self.kind\n",
    "        self.pos0_to_id = {p[0]: i for i, p in enumerate(self.pos)}\n",
    "        self.make_cv(0)\n",
    "\n",
    "    def get_ids_from_batch(self, batch_ids, train=True):\n",
    "        if train:\n",
    "            pos = self.pos_tr[batch_ids]\n",
    "        else:\n",
    "            pos = self.pos_te[batch_ids]\n",
    "        return np.asarray([self.pos0_to_id[p[0]] for p in pos])\n",
    "\n",
    "    def make_cv(self, i):\n",
    "        te = np.arange(len(self.pos)) % 10 == i\n",
    "        #te = np.arange(len(pos))>(len(pos)*0.9)\n",
    "        pos = self.pos\n",
    "        if self.all_train:\n",
    "            self.pos_tr = pos\n",
    "            self.pos_te = pos[0]\n",
    "            self.label_tr = self.label\n",
    "            self.label_te = self.label[0]\n",
    "            if self.has_pre:\n",
    "                pos_pre = self.pos_pre\n",
    "                self.pos_pre_tr = pos_pre\n",
    "                self.pos_pre_te = pos_pre[0]\n",
    "        elif self.all_test:\n",
    "            self.pos_tr = pos[0]\n",
    "            self.pos_te = pos\n",
    "            self.label_tr = self.label[0]\n",
    "            self.label_te = self.label\n",
    "            if self.has_pre:\n",
    "                pos_pre = self.pos_pre\n",
    "                self.pos_pre_tr = pos_pre[0]\n",
    "                self.pos_pre_te = pos_pre\n",
    "        else:\n",
    "            self.pos_tr = pos[~te]\n",
    "            self.pos_te = pos[te]\n",
    "            self.label_tr = self.label[~te]\n",
    "            self.label_te = self.label[te]\n",
    "            if self.has_pre:\n",
    "                pos_pre = self.pos_pre\n",
    "                self.pos_pre_tr = pos_pre[~te]\n",
    "                self.pos_pre_te = pos_pre[te]\n",
    "\n",
    "    '''\n",
    "    Batched letters in batched sentences are yeilded sequentially.\n",
    "    If the length of sentences are different in the batch,\n",
    "    We padding the ends of sentences by -1 after shorter sentences are finished.\n",
    "    arg: batch_ids, an array of ids for sentences.\n",
    "    return : an array of letters.  \n",
    "    '''\n",
    "\n",
    "    def sequence(self, batch_ids, train=True):\n",
    "        if train:\n",
    "            pos = self.pos_tr[batch_ids]\n",
    "        else:\n",
    "            pos = self.pos_te[batch_ids]\n",
    "        ids = pos[:, 0]\n",
    "        end = pos[:, 1] - 1\n",
    "        xs = self.data[ids]\n",
    "        yield xs.copy(), np.ones(len(xs), dtype=np.bool)\n",
    "        dif = ids < end\n",
    "        while np.any(dif):\n",
    "            ids = ids + dif\n",
    "            xs[~dif] = self.padding_symbol\n",
    "            xs[dif] = self.data[ids][dif]\n",
    "            yield xs.copy(), dif\n",
    "            dif = ids < end\n",
    "\n",
    "    def private_sequence_bothway(self, pos, data, bsize):\n",
    "        offset = pos[:, 0]\n",
    "        topside = pos[:, 1]\n",
    "        rem = pos[:, 1] - offset\n",
    "        k = np.max(rem)\n",
    "        xs = np.zeros((2, bsize), dtype=np.int32)\n",
    "        while k > 0:\n",
    "            k = k - 1\n",
    "            inRange = k < rem\n",
    "            xs[1, ~inRange] = self.padding_symbol\n",
    "            xs[1, inRange] = data[offset[inRange] + k]\n",
    "            xs[0, ~inRange] = self.padding_symbol\n",
    "            xs[0, inRange] = data[topside[inRange] - 1 - k]\n",
    "            yield xs[0].copy(), xs[1].copy(), inRange\n",
    "\n",
    "    def sequence_bothway_seq2seq(self, batch_ids, train=True):\n",
    "        t = [[], [], [], []]\n",
    "        if train:\n",
    "            pos_pre = self.pos_pre_tr[batch_ids]\n",
    "            pos = self.pos_tr[batch_ids]\n",
    "        else:\n",
    "            pos_pre = self.pos_pre_te[batch_ids]\n",
    "            pos = self.pos_te[batch_ids]\n",
    "        for xs, xs_rev, flags in self.private_sequence_bothway(\n",
    "                pos, self.data, len(batch_ids)):\n",
    "            t[0].append(xs)\n",
    "            t[1].append(xs_rev)\n",
    "        for xs, xs_rev, flags in self.private_sequence_bothway(\n",
    "                pos_pre, self.data_pre, len(batch_ids)):\n",
    "            t[2].append(xs)\n",
    "            t[3].append(xs_rev)\n",
    "\n",
    "        for i, (xs, xs_rev) in enumerate(zip(t[2] + t[0], t[1] + t[3])):\n",
    "            is_change = (i == len(t[2]) - 1, i == len(t[1]) - 1)\n",
    "            yield xs, xs_rev, is_change\n",
    "\n",
    "    def sequence_bothway(self, batch_ids, train=True):\n",
    "        if train:\n",
    "            pos = self.pos_tr[batch_ids]\n",
    "        else:\n",
    "            pos = self.pos_te[batch_ids]\n",
    "        offset = pos[:, 0]\n",
    "        topside = pos[:, 1]\n",
    "        rem = pos[:, 1] - offset\n",
    "        k = np.max(rem)\n",
    "        xs = np.zeros((2, len(batch_ids)), dtype=np.int32)\n",
    "        while k > 0:\n",
    "            k = k - 1\n",
    "            inRange = k < rem\n",
    "            xs[1, ~inRange] = self.padding_symbol\n",
    "            xs[1, inRange] = self.data[offset[inRange] + k]\n",
    "            xs[0, ~inRange] = self.padding_symbol\n",
    "            xs[0, inRange] = self.data[topside[inRange] - 1 - k]\n",
    "            yield xs[0].copy(), xs[1].copy(), inRange\n",
    "\n",
    "    def sequence_bothway_2D(self, batch_ids, train=True):\n",
    "        for xs, xs_rev, inRange in self.sequence_bothway(batch_ids, train):\n",
    "            xs_2D = np.asarray([self.id_to_vec[x] for x in xs])\n",
    "            xs_rev_2D = np.asarray([self.id_to_vec[x] for x in xs_rev])\n",
    "            yield xs_2D, xs_rev_2D, inRange\n",
    "\n",
    "    '''\n",
    "    Called from the inside.\n",
    "    The sentences are sorted by the length and suffled.\n",
    "    '''\n",
    "\n",
    "    def shuffle(self, shuffle_block_size, train):\n",
    "        if train:\n",
    "            lengths = self.pos_tr[:, 1] - self.pos_tr[:, 0]\n",
    "            perturbation = np.random.uniform(0, 0.999, len(lengths))\n",
    "        else:\n",
    "            lengths = self.pos_te[:, 1] - self.pos_te[:, 0]\n",
    "            perturbation = np.zeros(len(lengths))\n",
    "\n",
    "        sorted_order = np.argsort(lengths + perturbation)\n",
    "        '''When the length of data is not devied by block_size, the set of blocks must have another block.'''\n",
    "        rem = int(len(lengths) % shuffle_block_size != 0)\n",
    "        rem = 0\n",
    "        blocks = np.arange(len(lengths) / shuffle_block_size + rem)\n",
    "        if train:\n",
    "            np.random.shuffle(blocks)\n",
    "        return blocks, sorted_order\n",
    "\n",
    "    '''\n",
    "    Yields batched sentences from the starts to the ends simulteniously.  \n",
    "    return: an array of ids for sentences.\n",
    "    '''\n",
    "\n",
    "    def batched_sentences(self, batch_size=16, train=True):\n",
    "        blocks, sorted_order = self.shuffle(batch_size, train)\n",
    "        for b in blocks:\n",
    "            b = int(b)\n",
    "            yield sorted_order[b * batch_size:(b + 1) * batch_size]\n",
    "\n",
    "    def get_labels(self, batch_ids, train=True):\n",
    "        if self.label is None:\n",
    "            return None\n",
    "        if train:\n",
    "            return self.label_tr[batch_ids]\n",
    "        else:\n",
    "            return self.label_te[batch_ids]\n",
    "\n",
    "    def get_len(self, batch_ids, train=True):\n",
    "        if train:\n",
    "            return np.max(self.pos_tr[batch_ids][:, 1] -\n",
    "                          self.pos_tr[batch_ids][:, 0])\n",
    "        else:\n",
    "            return np.max(self.pos_te[batch_ids][:, 1] -\n",
    "                          self.pos_te[batch_ids][:, 0])\n",
    "\n",
    "    def prepare_w2v_jawiki(self, w2v_model, wd_to_id, wd_set):\n",
    "        def get_id(wd):\n",
    "            if wd.decode('utf-8') not in w2v_model.vocab:\n",
    "                print((\"Exception:\", wd, wd_set[wd]))\n",
    "                return np.random.normal(size=w2v_model.vector_size)\n",
    "            else:\n",
    "                return w2v_model[wd.decode('utf-8')]\n",
    "\n",
    "        id_to_vec = {\n",
    "            wd_to_id[wd]: np.asarray(get_id(wd), dtype=np.float32)\n",
    "            for wd in list(wd_to_id.keys())\n",
    "        }\n",
    "        id_to_vec[self.start_symbol] = np.zeros(\n",
    "            w2v_model.vector_size, dtype=np.float32)\n",
    "        id_to_vec[self.end_symbol] = np.zeros(\n",
    "            w2v_model.vector_size, dtype=np.float32)\n",
    "        id_to_vec[self.padding_symbol] = np.zeros(\n",
    "            w2v_model.vector_size, dtype=np.float32)\n",
    "        self.id_to_vec = id_to_vec\n",
    "        self.vec_size = w2v_model.vector_size\n",
    "\n",
    "    def sentence_2D_batch(self, batch_ids, train=True):\n",
    "        max_len = self.get_len(batch_ids, train=train)\n",
    "        imgs = np.zeros(\n",
    "            (len(batch_ids), max_len, self.vec_size), dtype=np.float32)\n",
    "\n",
    "        for i, (xs, dif) in enumerate(self.sequence(batch_ids, train=train)):\n",
    "            for b, wid in enumerate(xs):\n",
    "                imgs[b][i] = self.id_to_vec[wid]\n",
    "        return imgs\n",
    "\n",
    "    def sentence_1D_batch(self, batch_ids, train=True):\n",
    "        max_len = self.get_len(batch_ids, train=train)\n",
    "        ids = np.zeros((len(batch_ids), max_len), dtype=np.int32)\n",
    "\n",
    "        for i, (xs, dif) in enumerate(self.sequence(batch_ids, train=train)):\n",
    "            for b, wid in enumerate(xs):\n",
    "                ids[b][i] = wid\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T08:46:48.156947Z",
     "start_time": "2017-12-07T08:46:48.019757Z"
    }
   },
   "outputs": [],
   "source": [
    "data = DataGenerator(\n",
    "    \"data/Argumentation_FA_edu_data.txt\", \"data/Argumentation_FA_edu_data_pre.txt\", fmt=\"2-labeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T01:55:00.271473Z",
     "start_time": "2017-12-06T01:33:09.730805Z"
    }
   },
   "outputs": [],
   "source": [
    "#import imp\n",
    "# imp.reload(datagen)\n",
    "data = DataGenerator(\n",
    "    \"data/Argumentation_FA_edu_data.txt\", \"data/Argumentation_FA_edu_data_pre.txt\", fmt=\"2-labeled\")\n",
    "\n",
    "\n",
    "B_SIZE = 64  # 128\n",
    "\n",
    "learner = models.Simple_bothway_seq2seq(vocab_size=data.kind,   class_size=KIND,\n",
    "                                        dim_embed=200, dim1=600, dim2=600, dim=200, num_use_out=2)\n",
    "whole_epoc = 0\n",
    "\n",
    "learner.optimizer = optimizers.Adam()\n",
    "learner.optimizer.setup(learner)\n",
    "\n",
    "schedule = [\n",
    "    [0.1, 20],\n",
    "    #[0.03, 5],\n",
    "    #[0.01, 10]#,\n",
    "    #[0.003, 10],\n",
    "    #[0.001, 10]\n",
    "]\n",
    "\n",
    "while len(schedule) > 0:\n",
    "    #learner.optimizer.lr = schedule[0][0]\n",
    "    schedule[0][1] -= 1\n",
    "    if schedule[0][1] <= 0:\n",
    "        schedule = schedule[1:]\n",
    "        model_file = 'model/Argumentation_FA_classify_model_new(5labels)_' + \\\n",
    "            str.zfill(str(whole_epoc), 2)\n",
    "        serializers.save_npz(model_file + '.npz', learner)\n",
    "    whole_epoc += 1\n",
    "    for train in [True, False]:\n",
    "        s_top5, s_ac, n = 0.0, 0.0, 0\n",
    "        start = time.time()\n",
    "        for sid in data.batched_sentences(B_SIZE, train=train):\n",
    "            labels = data.get_labels(sid, train=train)\n",
    "            xs = None\n",
    "            for new_xs, new_xs_rev, is_change in data.sequence_bothway_seq2seq(sid, train=train):\n",
    "                if xs is not None:\n",
    "                    if train:\n",
    "                        learner.only_feed_for_learn(\n",
    "                            (xp.asarray(xs), xp.asarray(xs_rev)))\n",
    "                    else:\n",
    "                        learner.only_feed((xp.asarray(xs), xp.asarray(xs_rev)))\n",
    "                if is_change[0]:\n",
    "                    learner.connect_mid()\n",
    "                if is_change[1]:\n",
    "                    learner.connect_mid_rev()\n",
    "                xs, xs_rev = new_xs, new_xs_rev\n",
    "            if train:\n",
    "                correct, score_top5 = learner.feed_for_learn(\n",
    "                    (xp.asarray(xs), xp.asarray(xs_rev)), labels[:, 0])\n",
    "                learner.update()\n",
    "            else:\n",
    "                correct, score_top5 = learner.check(\n",
    "                    (xp.asarray(xs), xp.asarray(xs_rev)), labels[:, 0])\n",
    "                learner.reset_state()\n",
    "            s_top5 += np.sum(score_top5)\n",
    "            s_ac += np.sum(correct)\n",
    "            n += len(sid)\n",
    "        end = time.time() - start\n",
    "        name = {True: 'Tr', False: 'Te'}\n",
    "        print('.', end=' ')\n",
    "        print(\"%02d\" % whole_epoc, name[train], 'done:', n, end=' ')\n",
    "        print('acc:%7.4f' % (s_ac / n), 'top5_scr:%7.4f' %\n",
    "              (s_top5 / n), 'time:%5.1f' % end, end=' ')\n",
    "        if train:\n",
    "            print('lr=', learner.optimizer.lr)\n",
    "        else:\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-07T08:44:54.435Z"
    }
   },
   "outputs": [],
   "source": [
    "from chainer import serializers\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "learner = models.Simple_bothway_seq2seq(\n",
    "    vocab_size=data.kind,\n",
    "    class_size=KIND,\n",
    "    dim_embed=200,\n",
    "    dim1=600,\n",
    "    dim2=600,\n",
    "    dim=200,\n",
    "    num_use_out=2)\n",
    "\n",
    "serializers.load_npz(\"model/Argumentation_FA_classify_model_new(5labels)_19.npz\", learner)\n",
    "\n",
    "with open('data/Argumentation_FA_id_to_lb.pickle', mode='rb') as f:\n",
    "    id_to_code = pickle.load(f)\n",
    "KIND = len(id_to_code)\n",
    "data = DataGenerator(\n",
    "    \"data/Argumentation_FA_edu_data.txt\", \"data/Argumentation_FA_edu_data_pre.txt\", fmt=\"2-labeled\")\n",
    "\n",
    "pd.DataFrame(np.array(list(id_to_code.items())).T)\n",
    "y_pred = []\n",
    "y_test = []\n",
    "y_id = []\n",
    "train = False\n",
    "B_SIZE = 64\n",
    "for sid in data.batched_sentences(B_SIZE, train=train):\n",
    "    labels = data.get_labels(sid, train=train)\n",
    "    xs = None\n",
    "    for new_xs, new_xs_rev, is_change in data.sequence_bothway_seq2seq(\n",
    "            sid, train=train):\n",
    "        if xs is not None:\n",
    "            learner.only_feed((xp.asarray(xs), xp.asarray(xs_rev)))\n",
    "        if is_change[0]:\n",
    "            learner.connect_mid()\n",
    "        if is_change[1]:\n",
    "            learner.connect_mid_rev()\n",
    "        xs, xs_rev = new_xs, new_xs_rev\n",
    "    yss, out = learner.feed((xp.asarray(xs), xp.asarray(xs_rev)))\n",
    "    learner.reset_state()\n",
    "    y_pred += np.argmax(out, axis=1).tolist()\n",
    "    y_test += labels[:, 0].tolist()\n",
    "    y_id += sid.tolist()\n",
    "\n",
    "print(Counter(y_pred), max(y_test))\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-12-07T08:44:54.950Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/Argumentation_FA_id_to_lb.pickle', mode='rb') as f:\n",
    "    id_to_code = pickle.load(f)\n",
    "print(KIND)\n",
    "label_table = [\n",
    "    list(set(y_pred)), [id_to_code[e] for e in set(y_pred)]\n",
    "]\n",
    "\n",
    "pd.DataFrame(label_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:38.704401Z",
     "start_time": "2017-12-06T02:02:38.701196Z"
    }
   },
   "outputs": [],
   "source": [
    "id_to_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:39.371570Z",
     "start_time": "2017-12-06T02:02:39.346754Z"
    }
   },
   "outputs": [],
   "source": [
    "srt = np.argsort(y_id)\n",
    "result = np.array([y_id, [id_to_code[e] for e in y_pred], y_pred,\n",
    "                   [id_to_code[e] for e in y_test], y_test\n",
    "                   ])[:, srt].T\n",
    "result[:, 0] = result[:, 0].astype(int) + 2\n",
    "df = pd.DataFrame(\n",
    "    result, columns=[\"行番号\", \"予測ラベルname\", \"予測ラベルID\", \"既存ラベルname\", \"既存ラベルID\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:40.167618Z",
     "start_time": "2017-12-06T02:02:40.158280Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/Argumentation_FA_result_v0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:41.883092Z",
     "start_time": "2017-12-06T02:02:41.878433Z"
    }
   },
   "outputs": [],
   "source": [
    "list(id_to_code.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:42.385859Z",
     "start_time": "2017-12-06T02:02:42.371447Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #class_names = [    \"Ontask\", \"Offtask\"]\n",
    "# class_names = list(id_to_code.values())\n",
    "# class_names.remove('grounded and qualified claim')\n",
    "\n",
    "# print(class_names)\n",
    "\n",
    "# print(set(y_pred))\n",
    "\n",
    "# print((classification_report(y_test, y_pred, target_names=class_names)))\n",
    "\n",
    "\n",
    "# def plot_confusion_matrix(cm,\n",
    "#                           classes,\n",
    "#                           normalize=False,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=plt.cm.Reds):\n",
    "\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     # plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(\n",
    "#             list(range(cm.shape[0])), list(range(cm.shape[1]))):\n",
    "#         plt.text(\n",
    "#             j,\n",
    "#             i,\n",
    "#             cm[i, j],\n",
    "#             horizontalalignment=\"center\",\n",
    "#             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plot_confusion_matrix(\n",
    "#     cnf_matrix,\n",
    "#     classes=class_names,\n",
    "#     title='Confusion matrix, without normalization')\n",
    "# plt.savefig(\"figure/Argumentation_FA_without_Nomalize_sbs.png\")\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plot_confusion_matrix(\n",
    "#     cnf_matrix,\n",
    "#     classes=class_names,\n",
    "#     normalize=True,\n",
    "#     title='Normalized confusion matrix')\n",
    "\n",
    "# plt.savefig(\"figure/Argumentation_FA_Nomalize_sbs.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:43.390767Z",
     "start_time": "2017-12-06T02:02:42.857995Z"
    }
   },
   "outputs": [],
   "source": [
    "#class_names = [    \"Ontask\", \"Offtask\"]\n",
    "class_names = list(id_to_code.values())\n",
    "class_names.remove('grounded and qualified claim')\n",
    "\n",
    "print(class_names)\n",
    "\n",
    "print(set(y_pred))\n",
    "\n",
    "print((classification_report(y_test, y_pred, target_names=class_names)))\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    # plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = cm.round(decimals=4)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(\n",
    "            list(range(cm.shape[0])), list(range(cm.shape[1]))):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(\n",
    "    cnf_matrix,\n",
    "    classes=class_names,\n",
    "    title='Confusion matrix, without normalization')\n",
    "plt.savefig(\"figure/Argumentation_A_without_Nomalize_sbs.png\")\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(\n",
    "    cnf_matrix,\n",
    "    classes=class_names,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix')\n",
    "\n",
    "plt.savefig(\"figure/Argumentation_A_Nomalize_sbs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここからconfusion matrixの修正処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 現状のid_to_codeの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:48.857103Z",
     "start_time": "2017-12-06T02:02:48.852593Z"
    }
   },
   "outputs": [],
   "source": [
    "id_to_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testデータに含まれないラベルを削除(Arg_FAのとき、grou and qual claimを削除)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:51.847160Z",
     "start_time": "2017-12-06T02:02:51.842036Z"
    }
   },
   "outputs": [],
   "source": [
    "#id_to_code.pop(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:52.462799Z",
     "start_time": "2017-12-06T02:02:52.457629Z"
    }
   },
   "outputs": [],
   "source": [
    "id_to_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label変換用の辞書作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:02:54.945732Z",
     "start_time": "2017-12-06T02:02:54.939630Z"
    }
   },
   "outputs": [],
   "source": [
    "sort_label_dict = {key[0]:i for i, key in enumerate(counter.most_common())}\n",
    "label_change_dict = {i:sort_label_dict[k] for i, k in zip(id_to_code.keys(), id_to_code.values())}\n",
    "print(label_change_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-05T14:57:49.034747Z",
     "start_time": "2017-12-05T14:57:49.032788Z"
    }
   },
   "source": [
    "## class_name用の辞書を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:03:00.334418Z",
     "start_time": "2017-12-06T02:03:00.329744Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict = {i:key[0] for i, key in enumerate(counter.most_common())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラベルの変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:03:01.174818Z",
     "start_time": "2017-12-06T02:03:01.170544Z"
    }
   },
   "outputs": [],
   "source": [
    "changed_y_test = []\n",
    "for l in y_test:\n",
    "    changed_y_test.append(label_change_dict[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:03:03.393641Z",
     "start_time": "2017-12-06T02:03:03.389215Z"
    }
   },
   "outputs": [],
   "source": [
    "print(changed_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:03:06.221794Z",
     "start_time": "2017-12-06T02:03:06.217012Z"
    }
   },
   "outputs": [],
   "source": [
    "changed_y_pred = []\n",
    "for l in y_pred:\n",
    "    changed_y_pred.append(label_change_dict[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-06T02:03:06.675599Z",
     "start_time": "2017-12-06T02:03:06.671109Z"
    }
   },
   "outputs": [],
   "source": [
    "print(changed_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T10:53:15.429100Z",
     "start_time": "2017-12-07T10:53:15.424118Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T10:53:35.903596Z",
     "start_time": "2017-12-07T10:53:35.898552Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict[0] = \"Non-Argumentative\"\n",
    "label_dict[1] = \"Simple Claim\"\n",
    "label_dict[2] = \"Grounded Claim\"\n",
    "label_dict[3] = \"Qualified Claim\"\n",
    "label_dict[4] = \"G. and Q. Claim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T10:53:37.084629Z",
     "start_time": "2017-12-07T10:53:37.070176Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #class_names = [    \"Ontask\", \"Offtask\"]\n",
    "# class_names = list(label_dict.values())\n",
    "\n",
    "# print(class_names)\n",
    "\n",
    "# print(set(changed_y_pred))\n",
    "\n",
    "# print((classification_report(changed_y_test, changed_y_pred, target_names=class_names)))\n",
    "\n",
    "\n",
    "# def plot_confusion_matrix(cm,\n",
    "#                           classes,\n",
    "#                           normalize=False,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=plt.cm.Reds):\n",
    "\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     # plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(\n",
    "#             list(range(cm.shape[0])), list(range(cm.shape[1]))):\n",
    "#         plt.text(\n",
    "#             j,\n",
    "#             i,\n",
    "#             cm[i, j],\n",
    "#             horizontalalignment=\"center\",\n",
    "#             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(changed_y_test, changed_y_pred)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plot_confusion_matrix(\n",
    "#     cnf_matrix,\n",
    "#     classes=class_names,\n",
    "#     title='Confusion matrix, without normalization')\n",
    "# plt.savefig(\"figure/Argumentation_FA_without_Nomalize_sbs.png\")\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plot_confusion_matrix(\n",
    "#     cnf_matrix,\n",
    "#     classes=class_names,\n",
    "#     normalize=True,\n",
    "#     title='Normalized confusion matrix')\n",
    "\n",
    "# plt.savefig(\"figure/Argumentation_FA_Nomalize_sbs.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T10:54:20.760769Z",
     "start_time": "2017-12-07T10:54:20.161756Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#class_names = [    \"Ontask\", \"Offtask\"]\n",
    "class_names = list(label_dict.values())\n",
    "class_names.remove('G. and Q. Claim')\n",
    "\n",
    "print(class_names)\n",
    "\n",
    "print(set(changed_y_pred))\n",
    "\n",
    "print((classification_report(changed_y_test, changed_y_pred, target_names=class_names)))\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    # plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, horizontalalignment=\"right\")\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = cm.round(decimals=2)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(\n",
    "            list(range(cm.shape[0])), list(range(cm.shape[1]))):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"silver\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(changed_y_test, changed_y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(12, 12))\n",
    "plot_confusion_matrix(\n",
    "    cnf_matrix,\n",
    "    classes=class_names,\n",
    "    title='Confusion matrix, without normalization')\n",
    "plt.savefig(\"figure/Argumentation_FA_without_Nomalize_sbs.png\")\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(12, 12))\n",
    "plot_confusion_matrix(\n",
    "    cnf_matrix,\n",
    "    classes=class_names,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix')\n",
    "\n",
    "plt.savefig(\"figure/Argumentation_FA_Nomalize_sbs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
